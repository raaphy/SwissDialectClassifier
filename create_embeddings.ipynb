{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-04-24T12:25:08.894220Z",
     "end_time": "2023-04-24T12:25:13.451763Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import gdi_loader as gdi\n",
    "import bert_swiss_lm as bsl\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at /Users/raphael/Downloads/bert-swiss-lm were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at ZurichNLP/swissbert were not used when initializing XmodModel: ['lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing XmodModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XmodModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XmodModel were not initialized from the model checkpoint at ZurichNLP/swissbert and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Setup loader\n",
    "loader = gdi.GdiLoader(set_path=\"/Users/raphael/Downloads/gdi-vardial-2019/\")\n",
    "# Set up the two BERT embedders\n",
    "bert_swiss_lm_embedder = bsl.BertSwissLm(\"/Users/raphael/Downloads/bert-swiss-lm\")\n",
    "swiss_bert_embedder = bsl.BertSwissLm(\"ZurichNLP/swissbert\", set_default_language_to_de_CH=True)\n",
    "# Load GDI data\n",
    "train_data = loader.create_dataframe(which_type=\"train\")\n",
    "dev_data = loader.create_dataframe(which_type=\"dev\")\n",
    "test_data = loader.create_dataframe(which_type=\"gold\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-24T12:25:13.461492Z",
     "end_time": "2023-04-24T12:25:21.574814Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.329530000686646\n"
     ]
    }
   ],
   "source": [
    "# Embed data twice, once with the BERT model from Michael Jungo and once with SwissBERT\n",
    "# This takes approximately 1 hour\n",
    "start = time.time()\n",
    "train_embedding_df = bert_swiss_lm_embedder.add_sentence_embedding_to_df(train_data)\n",
    "dev_embedding_df = bert_swiss_lm_embedder.add_sentence_embedding_to_df(dev_data)\n",
    "test_embedding_df = bert_swiss_lm_embedder.add_sentence_embedding_to_df(test_data)\n",
    "\n",
    "train_swissbert_embedding_df = swiss_bert_embedder.add_sentence_embedding_to_df(train_data)\n",
    "dev_swissbert_embedding_df = swiss_bert_embedder.add_sentence_embedding_to_df(dev_data)\n",
    "test_swissbert_embedding_df = swiss_bert_embedder.add_sentence_embedding_to_df(test_data)\n",
    "print(time.time() - start)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-24T12:25:21.580029Z",
     "end_time": "2023-04-24T12:25:33.916325Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# Save the embeddings to disk for later use\n",
    "if not os.path.exists(\"data\"):\n",
    "    os.mkdir(\"data\")\n",
    "train_embedding_df.to_feather(\"data/train_embedding_bert_swiss_lm.feather\")\n",
    "dev_embedding_df.to_feather(\"data/dev_embedding_bert_swiss_lm.feather\")\n",
    "test_embedding_df.to_feather(\"data/test_embedding_bert_swiss_lm.feather\")\n",
    "\n",
    "train_swissbert_embedding_df.to_feather(\"data/train_embedding_swissbert.feather\")\n",
    "test_swissbert_embedding_df.to_feather(\"data/test_embedding_swissbert.feather\")\n",
    "dev_swissbert_embedding_df.to_feather(\"data/dev_embedding_swissbert.feather\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-24T12:25:33.921147Z",
     "end_time": "2023-04-24T12:25:33.961115Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "swiss_dial",
   "language": "python",
   "name": "swiss_dial"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

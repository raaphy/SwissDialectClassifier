{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from tokenizers import ByteLevelBPETokenizer\n",
    "import my_predictor as mp\n",
    "import gdi_loader as gdi\n",
    "from sklearn import svm\n",
    "import bert_swiss_lm as bsl\n",
    "import itertools\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "my_predictor = mp.MyPredictor(\"train_embedding_bert_swiss_lm.feather\", \"dev_embedding_bert_swiss_lm.feather\", None)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "my_predictor.fit()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          BE       0.91      0.93      0.92      3750\n",
      "          BS       0.90      0.88      0.89      3269\n",
      "          LU       0.92      0.85      0.88      3390\n",
      "          ZH       0.89      0.95      0.92      3870\n",
      "\n",
      "    accuracy                           0.90     14279\n",
      "   macro avg       0.91      0.90      0.90     14279\n",
      "weighted avg       0.91      0.90      0.90     14279\n",
      "\n",
      "Dev set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          BE       0.63      0.62      0.62      1053\n",
      "          BS       0.71      0.59      0.65      1528\n",
      "          LU       0.61      0.47      0.53      1017\n",
      "          ZH       0.56      0.86      0.68       932\n",
      "\n",
      "    accuracy                           0.63      4530\n",
      "   macro avg       0.63      0.64      0.62      4530\n",
      "weighted avg       0.64      0.63      0.62      4530\n",
      "\n"
     ]
    }
   ],
   "source": [
    "my_predictor.predict_all()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          BE       0.78      0.83      0.81      3750\n",
      "          BS       0.74      0.73      0.73      3269\n",
      "          LU       0.74      0.67      0.71      3390\n",
      "          ZH       0.80      0.82      0.81      3870\n",
      "\n",
      "    accuracy                           0.77     14279\n",
      "   macro avg       0.76      0.76      0.76     14279\n",
      "weighted avg       0.77      0.77      0.77     14279\n",
      "\n",
      "Dev set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          BE       0.57      0.60      0.58      1053\n",
      "          BS       0.68      0.54      0.60      1528\n",
      "          LU       0.53      0.45      0.49      1017\n",
      "          ZH       0.57      0.81      0.67       932\n",
      "\n",
      "    accuracy                           0.59      4530\n",
      "   macro avg       0.59      0.60      0.58      4530\n",
      "weighted avg       0.60      0.59      0.59      4530\n",
      "\n"
     ]
    }
   ],
   "source": [
    "my_predictor_pooler = mp.MyPredictor(\"train_embedding_bert_swiss_lm.feather\",\n",
    "                                     \"dev_embedding_bert_swiss_lm.feather\",\n",
    "                                     None,\n",
    "                                     [\"sentence_embedding_first_state\", \"audio\"],\n",
    "                                     audio_length=10)\n",
    "\n",
    "my_predictor_pooler.fit()\n",
    "my_predictor_pooler.predict_all()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'s'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "File \u001B[0;32m~/opt/miniconda3/envs/swiss_dial/lib/python3.10/site-packages/pandas/core/indexes/base.py:3802\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[0;34m(self, key, method, tolerance)\u001B[0m\n\u001B[1;32m   3801\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 3802\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcasted_key\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3803\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n",
      "File \u001B[0;32m~/opt/miniconda3/envs/swiss_dial/lib/python3.10/site-packages/pandas/_libs/index.pyx:138\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m~/opt/miniconda3/envs/swiss_dial/lib/python3.10/site-packages/pandas/_libs/index.pyx:165\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mpandas/_libs/hashtable_class_helper.pxi:5745\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mpandas/_libs/hashtable_class_helper.pxi:5753\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;31mKeyError\u001B[0m: 's'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[8], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m my_predictor_with_audio \u001B[38;5;241m=\u001B[39m mp\u001B[38;5;241m.\u001B[39mMyPredictor(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain_embedding_bert_swiss_lm.feather\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdev_embedding_bert_swiss_lm.feather\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msentence_embedding_pooler\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m----> 2\u001B[0m \u001B[43mmy_predictor_with_audio\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      3\u001B[0m my_predictor_with_audio\u001B[38;5;241m.\u001B[39mpredict_all()\n",
      "File \u001B[0;32m~/development/ntnu/text_analysis/swiss/my_predictor.py:21\u001B[0m, in \u001B[0;36mMyPredictor.fit\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     19\u001B[0m training_embeddings \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mread_feather(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpath_train_embeddings)\n\u001B[1;32m     20\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclf \u001B[38;5;241m=\u001B[39m svm\u001B[38;5;241m.\u001B[39mSVC()\n\u001B[0;32m---> 21\u001B[0m embedding \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgenerate_embedding\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtraining_embeddings\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     22\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclf\u001B[38;5;241m.\u001B[39mfit(embedding\u001B[38;5;241m.\u001B[39mtolist(), training_embeddings[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlabel\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;241m.\u001B[39mtolist())\n",
      "File \u001B[0;32m~/development/ntnu/text_analysis/swiss/my_predictor.py:42\u001B[0m, in \u001B[0;36mMyPredictor.generate_embedding\u001B[0;34m(self, training_embeddings)\u001B[0m\n\u001B[1;32m     41\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mgenerate_embedding\u001B[39m(\u001B[38;5;28mself\u001B[39m, training_embeddings):\n\u001B[0;32m---> 42\u001B[0m     concatenated \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mconcat([training_embeddings[col] \u001B[38;5;28;01mfor\u001B[39;00m col \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mwhich_embedding], axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m     43\u001B[0m     \u001B[38;5;66;03m# change name of column\u001B[39;00m\n\u001B[1;32m     44\u001B[0m     concatenated\u001B[38;5;241m.\u001B[39mcolumns \u001B[38;5;241m=\u001B[39m [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124membedding\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "File \u001B[0;32m~/development/ntnu/text_analysis/swiss/my_predictor.py:42\u001B[0m, in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m     41\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mgenerate_embedding\u001B[39m(\u001B[38;5;28mself\u001B[39m, training_embeddings):\n\u001B[0;32m---> 42\u001B[0m     concatenated \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mconcat([\u001B[43mtraining_embeddings\u001B[49m\u001B[43m[\u001B[49m\u001B[43mcol\u001B[49m\u001B[43m]\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m col \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mwhich_embedding], axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m     43\u001B[0m     \u001B[38;5;66;03m# change name of column\u001B[39;00m\n\u001B[1;32m     44\u001B[0m     concatenated\u001B[38;5;241m.\u001B[39mcolumns \u001B[38;5;241m=\u001B[39m [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124membedding\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "File \u001B[0;32m~/opt/miniconda3/envs/swiss_dial/lib/python3.10/site-packages/pandas/core/frame.py:3807\u001B[0m, in \u001B[0;36mDataFrame.__getitem__\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   3805\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns\u001B[38;5;241m.\u001B[39mnlevels \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m   3806\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_getitem_multilevel(key)\n\u001B[0;32m-> 3807\u001B[0m indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3808\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_integer(indexer):\n\u001B[1;32m   3809\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m [indexer]\n",
      "File \u001B[0;32m~/opt/miniconda3/envs/swiss_dial/lib/python3.10/site-packages/pandas/core/indexes/base.py:3804\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[0;34m(self, key, method, tolerance)\u001B[0m\n\u001B[1;32m   3802\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine\u001B[38;5;241m.\u001B[39mget_loc(casted_key)\n\u001B[1;32m   3803\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[0;32m-> 3804\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01merr\u001B[39;00m\n\u001B[1;32m   3805\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[1;32m   3806\u001B[0m     \u001B[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001B[39;00m\n\u001B[1;32m   3807\u001B[0m     \u001B[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001B[39;00m\n\u001B[1;32m   3808\u001B[0m     \u001B[38;5;66;03m#  the TypeError.\u001B[39;00m\n\u001B[1;32m   3809\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_indexing_error(key)\n",
      "\u001B[0;31mKeyError\u001B[0m: 's'"
     ]
    }
   ],
   "source": [
    "my_predictor_with_audio = mp.MyPredictor(\"train_embedding_bert_swiss_lm.feather\", \"dev_embedding_bert_swiss_lm.feather\", None, \"sentence_embedding_pooler\")\n",
    "my_predictor_with_audio.fit()\n",
    "my_predictor_with_audio.predict_all()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "my_predictor_pooler.fit()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:  6e-05 kernel:  linear\n",
      "Training set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          BE       0.99      0.99      0.99      3750\n",
      "          BS       0.99      0.98      0.99      3269\n",
      "          LU       0.99      1.00      0.99      3390\n",
      "          ZH       0.99      0.99      0.99      3870\n",
      "\n",
      "    accuracy                           0.99     14279\n",
      "   macro avg       0.99      0.99      0.99     14279\n",
      "weighted avg       0.99      0.99      0.99     14279\n",
      "\n",
      "Dev set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          BE       0.20      0.24      0.22      1053\n",
      "          BS       0.62      0.39      0.48      1528\n",
      "          LU       0.29      0.14      0.18      1017\n",
      "          ZH       0.38      0.73      0.50       932\n",
      "\n",
      "    accuracy                           0.37      4530\n",
      "   macro avg       0.37      0.37      0.34      4530\n",
      "weighted avg       0.40      0.37      0.36      4530\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in (0.00006,):\n",
    "    # best C: 0.00006 (macro f1 0.33)\n",
    "    # standard_Scaler= True: 0.0006 (accuracy 0.31) schlechter als 0.00006 (accuracy 0.38)\n",
    "    # standard_Scaler= False: 0.0006 (accuracy )  als normalize_each_vector=False 0.00006 (accuracy 0.31)\n",
    "#    for standard_scalar in (False, True):\n",
    "    for kernel in (\"linear\",):\n",
    "        standard_scalar = True\n",
    "        norm = False\n",
    "        my_predictor_audio = mp.MyPredictor(\"train_embedding_bert_swiss_lm.feather\",\n",
    "                                     \"dev_embedding_bert_swiss_lm.feather\",\n",
    "                                     None,\n",
    "                                            (\"audio\",),\n",
    "                                    normalize_each_vector=norm)\n",
    "\n",
    "        my_predictor_audio.fit(C=i, standard_scaler=standard_scalar, kernel=kernel)\n",
    "        print(\"C: \", i, \"kernel: \", kernel)\n",
    "        my_predictor_audio.predict_all()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "standard_scaler:  False normalize_each_vector:  False\n",
      "Training set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          BE       0.85      0.84      0.84      3750\n",
      "          BS       0.80      0.82      0.81      3269\n",
      "          LU       0.82      0.75      0.78      3390\n",
      "          ZH       0.81      0.87      0.84      3870\n",
      "\n",
      "    accuracy                           0.82     14279\n",
      "   macro avg       0.82      0.82      0.82     14279\n",
      "weighted avg       0.82      0.82      0.82     14279\n",
      "\n",
      "Dev set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          BE       0.66      0.59      0.62      1053\n",
      "          BS       0.80      0.77      0.79      1528\n",
      "          LU       0.81      0.57      0.67      1017\n",
      "          ZH       0.60      0.90      0.72       932\n",
      "\n",
      "    accuracy                           0.71      4530\n",
      "   macro avg       0.72      0.71      0.70      4530\n",
      "weighted avg       0.73      0.71      0.71      4530\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for standard_scalar in (False,):\n",
    "    for norm in (False,):\n",
    "        my_predictor_audio_gaussian = mp.MyPredictor(\"train_embedding_bert_swiss_lm.feather\",\n",
    "                                     \"dev_embedding_bert_swiss_lm.feather\",\n",
    "                                     None,\n",
    "                                                     (\"sentence_embedding_first_state\", \"audio\"),\n",
    "                                    normalize_each_vector=norm)\n",
    "\n",
    "        my_predictor_audio_gaussian.fit_gaussian_naive_bayes(standard_scaler=standard_scalar)\n",
    "        print(\"standard_scaler: \", standard_scalar, \"normalize_each_vector: \", norm)\n",
    "        my_predictor_audio_gaussian.predict_all()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6147505478251539\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          BE       0.60      0.62      0.61       242\n",
      "          BS       0.69      0.52      0.60       335\n",
      "          LU       0.69      0.49      0.57       235\n",
      "          ZH       0.48      0.84      0.61       188\n",
      "\n",
      "    accuracy                           0.60      1000\n",
      "   macro avg       0.61      0.62      0.60      1000\n",
      "weighted avg       0.63      0.60      0.60      1000\n",
      "\n"
     ]
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "1000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          BE       0.57      0.60      0.58      1053\n",
      "          BS       0.73      0.60      0.66      1528\n",
      "          LU       0.60      0.47      0.53      1017\n",
      "          ZH       0.56      0.82      0.67       932\n",
      "\n",
      "    accuracy                           0.62      4530\n",
      "   macro avg       0.62      0.62      0.61      4530\n",
      "weighted avg       0.63      0.62      0.61      4530\n",
      "\n",
      "[[-1.31001618 -0.7810659   0.86600119 -2.04481747]\n",
      " [-0.44720302  0.20401442 -1.02759569 -0.91909179]\n",
      " [-0.02500046 -0.37267663  0.1809242  -3.47945755]\n",
      " [ 0.86143844 -1.7048028  -0.58103523 -2.71862425]\n",
      " [ 0.53552571 -1.86106865 -0.65354833 -1.24230647]\n",
      " [-1.77664344 -1.62984643 -2.90404613  2.20583745]\n",
      " [-1.63378788 -0.85808199 -0.08675167  0.08348658]\n",
      " [-0.80958421 -2.19490501  1.04960575 -2.02077076]\n",
      " [-1.81817499  1.28206112 -0.93882105 -1.71235151]\n",
      " [-0.34390398 -1.44972304 -0.24034991 -1.36355317]]\n",
      "['LU' 'BS' 'LU' 'BE' 'BE' 'ZH' 'ZH' 'LU' 'BS' 'LU']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "for i in (1000,):\n",
    "    tokenizer = ByteLevelBPETokenizer()\n",
    "    df = pd.read_feather(\"train_embedding_bert_swiss_lm.feather\")\n",
    "    tokenizer.train_from_iterator(df['text'].tolist(), vocab_size=i, min_frequency=2)\n",
    "    encoded = tokenizer.encode_batch(df['text'].tolist())\n",
    "    tokenized = [e.tokens for e in encoded]\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    tfidf_weights = vectorizer.fit_transform([' '.join(tokens) for tokens in tokenized]).toarray()\n",
    "    gaus = svm.LinearSVC()\n",
    "    #gaus = svm.SVC(kernel='linear')\n",
    "    #gaus = GaussianNB()\n",
    "    #gaus = make_pipeline(StandardScaler(), gaus)\n",
    "    gaus.fit(tfidf_weights, df['label'].tolist())\n",
    "    df_dev = pd.read_feather(\"dev_embedding_bert_swiss_lm.feather\")\n",
    "    dev_tokenized = [e.tokens for e in tokenizer.encode_batch(df_dev['text'].tolist())]\n",
    "    dev_vectorized = vectorizer.transform([' '.join(tokens) for tokens in dev_tokenized]).toarray()\n",
    "    dev_predict = gaus.predict(dev_vectorized)\n",
    "  #  train_predict = gaus.predict(tfidf_weights)\n",
    "    #print(classification_report(df['label'].tolist(), train_predict))\n",
    "    print(i)\n",
    "    print(classification_report(df_dev['label'].tolist(), dev_predict))\n",
    "    print(gaus.decision_function(dev_vectorized)[0:10])\n",
    "    print(gaus.predict(dev_vectorized)[0:10])\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# For sentance_embedding and audio, GaussianNB is the best\n",
    "# For ByteLevelBPETokenizer, LinearSVC is the best\n",
    "# One can call LinearSVC.decision_function() to get features which can be used for classification"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import swiss_dialect_predictors as sdp"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "train_df = pd.read_feather(\"train_embedding_bert_swiss_lm.feather\")\n",
    "dev_df = pd.read_feather(\"dev_embedding_bert_swiss_lm.feather\")\n",
    "train_swissbert = pd.read_feather(\"train_embedding_swissbert.feather\")\n",
    "dev_swissbert = pd.read_feather(\"dev_embedding_swissbert.feather\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "tf-idf vocab size: 680\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          BE       0.87      0.85      0.86      3750\n",
      "          BS       0.82      0.84      0.83      3269\n",
      "          LU       0.84      0.78      0.81      3390\n",
      "          ZH       0.82      0.87      0.85      3870\n",
      "\n",
      "    accuracy                           0.84     14279\n",
      "   macro avg       0.84      0.84      0.84     14279\n",
      "weighted avg       0.84      0.84      0.84     14279\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          BE       0.67      0.62      0.64      1053\n",
      "          BS       0.81      0.79      0.80      1528\n",
      "          LU       0.82      0.58      0.68      1017\n",
      "          ZH       0.62      0.89      0.73       932\n",
      "\n",
      "    accuracy                           0.72      4530\n",
      "   macro avg       0.73      0.72      0.71      4530\n",
      "weighted avg       0.74      0.72      0.72      4530\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "svm_gaussiannb_predictor = sdp.SwissDialectPredictorSvmGaussianNB( enable_audio=True,\n",
    "                                                                   enable_sentance_embedding=True,\n",
    "                                                                   enable_byte_pair_tfidf=True,\n",
    "                                                                   normalize_each_vector=True,\n",
    "                                                                   last_classifier=GaussianNB())\n",
    "                                                                   #last_classifier=make_pipeline(StandardScaler(), TruncatedSVD(n_components=220), LinearSVC()))\n",
    "svm_gaussiannb_predictor.fit(train_df)\n",
    "train_predicted = svm_gaussiannb_predictor.predict(train_df)\n",
    "dev_predicted = svm_gaussiannb_predictor.predict(dev_df)\n",
    "# calculate f1 macro\n",
    "print(classification_report(train_df['label'].tolist(), train_predicted))\n",
    "print(classification_report(dev_df['label'].tolist(), dev_predicted))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          BE       0.43      0.73      0.54      1053\n",
      "          BS       0.72      0.56      0.63      1528\n",
      "          LU       0.70      0.27      0.39      1017\n",
      "          ZH       0.51      0.63      0.56       932\n",
      "\n",
      "    accuracy                           0.55      4530\n",
      "   macro avg       0.59      0.55      0.53      4530\n",
      "weighted avg       0.60      0.55      0.54      4530\n",
      "\n"
     ]
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "tf-idf vocab size: 680\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          BE       0.55      0.82      0.66      3750\n",
      "          BS       0.72      0.46      0.56      3269\n",
      "          LU       0.71      0.49      0.58      3390\n",
      "          ZH       0.64      0.69      0.66      3870\n",
      "\n",
      "    accuracy                           0.63     14279\n",
      "   macro avg       0.65      0.62      0.62     14279\n",
      "weighted avg       0.65      0.63      0.62     14279\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          BE       0.38      0.66      0.48      1053\n",
      "          BS       0.76      0.41      0.53      1528\n",
      "          LU       0.55      0.30      0.39      1017\n",
      "          ZH       0.46      0.66      0.54       932\n",
      "\n",
      "    accuracy                           0.49      4530\n",
      "   macro avg       0.54      0.51      0.49      4530\n",
      "weighted avg       0.57      0.49      0.49      4530\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from byte_pair_tfidf_vectorizer import BytePairTfidfVectorizer\n",
    "\n",
    "byte_pair_tfidf_vectorizer = BytePairTfidfVectorizer(vocab_size=1000, min_frequency=2)\n",
    "byte_pair_vectorized = byte_pair_tfidf_vectorizer.fit_transform(train_df[\"text\"].tolist())\n",
    "\n",
    "svm_linear = make_pipeline(StandardScaler(),TruncatedSVD(n_components=50), KNeighborsClassifier(n_neighbors=50))\n",
    "svm_linear.fit(byte_pair_vectorized, train_df[\"label\"].tolist())\n",
    "prediction = svm_linear.predict(byte_pair_vectorized)\n",
    "print(classification_report(train_df[\"label\"].tolist(), prediction))\n",
    "prediction_dev = svm_linear.predict(byte_pair_tfidf_vectorizer.transform(dev_df[\"text\"].tolist()))\n",
    "print(classification_report(dev_df[\"label\"].tolist(), prediction_dev))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enable_byte_pair_tfidf:  True enable_sentence_embedding:  True enable_audio:  True\n",
      "\n",
      "\n",
      "\n",
      "tf-idf vocab size: 680\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          BE       0.85      0.88      0.86      3750\n",
      "          BS       0.98      0.73      0.83      3269\n",
      "          LU       0.92      0.69      0.79      3390\n",
      "          ZH       0.69      0.97      0.80      3870\n",
      "\n",
      "    accuracy                           0.82     14279\n",
      "   macro avg       0.86      0.82      0.82     14279\n",
      "weighted avg       0.85      0.82      0.82     14279\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          BE       0.59      0.58      0.59      1053\n",
      "          BS       0.93      0.71      0.80      1528\n",
      "          LU       0.83      0.39      0.53      1017\n",
      "          ZH       0.49      0.97      0.65       932\n",
      "\n",
      "    accuracy                           0.66      4530\n",
      "   macro avg       0.71      0.66      0.64      4530\n",
      "weighted avg       0.74      0.66      0.66      4530\n",
      "\n",
      "enable_byte_pair_tfidf:  True enable_sentence_embedding:  True enable_audio:  False\n",
      "\n",
      "\n",
      "\n",
      "tf-idf vocab size: 680\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          BE       0.76      0.73      0.74      3750\n",
      "          BS       0.66      0.70      0.68      3269\n",
      "          LU       0.73      0.60      0.66      3390\n",
      "          ZH       0.70      0.79      0.74      3870\n",
      "\n",
      "    accuracy                           0.71     14279\n",
      "   macro avg       0.71      0.70      0.70     14279\n",
      "weighted avg       0.71      0.71      0.71     14279\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          BE       0.66      0.63      0.65      1053\n",
      "          BS       0.75      0.70      0.72      1528\n",
      "          LU       0.76      0.57      0.65      1017\n",
      "          ZH       0.59      0.85      0.70       932\n",
      "\n",
      "    accuracy                           0.69      4530\n",
      "   macro avg       0.69      0.69      0.68      4530\n",
      "weighted avg       0.70      0.69      0.68      4530\n",
      "\n",
      "enable_byte_pair_tfidf:  True enable_sentence_embedding:  False enable_audio:  True\n",
      "\n",
      "\n",
      "\n",
      "tf-idf vocab size: 680\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          BE       0.99      0.99      0.99      3750\n",
      "          BS       0.99      0.98      0.98      3269\n",
      "          LU       0.98      0.98      0.98      3390\n",
      "          ZH       0.97      0.99      0.98      3870\n",
      "\n",
      "    accuracy                           0.98     14279\n",
      "   macro avg       0.98      0.98      0.98     14279\n",
      "weighted avg       0.98      0.98      0.98     14279\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          BE       0.23      0.23      0.23      1053\n",
      "          BS       0.93      0.74      0.83      1528\n",
      "          LU       0.38      0.10      0.15      1017\n",
      "          ZH       0.44      0.95      0.61       932\n",
      "\n",
      "    accuracy                           0.52      4530\n",
      "   macro avg       0.50      0.51      0.45      4530\n",
      "weighted avg       0.54      0.52      0.49      4530\n",
      "\n",
      "enable_byte_pair_tfidf:  False enable_sentence_embedding:  True enable_audio:  True\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          BE       0.97      0.69      0.81      3750\n",
      "          BS       0.99      0.57      0.72      3269\n",
      "          LU       0.98      0.53      0.69      3390\n",
      "          ZH       0.49      0.99      0.65      3870\n",
      "\n",
      "    accuracy                           0.71     14279\n",
      "   macro avg       0.86      0.70      0.72     14279\n",
      "weighted avg       0.85      0.71      0.72     14279\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          BE       0.64      0.38      0.47      1053\n",
      "          BS       0.96      0.59      0.73      1528\n",
      "          LU       0.83      0.10      0.18      1017\n",
      "          ZH       0.32      0.99      0.49       932\n",
      "\n",
      "    accuracy                           0.51      4530\n",
      "   macro avg       0.69      0.52      0.47      4530\n",
      "weighted avg       0.72      0.51      0.50      4530\n",
      "\n",
      "enable_byte_pair_tfidf:  False enable_sentence_embedding:  True enable_audio:  False\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          BE       0.71      0.65      0.68      3750\n",
      "          BS       0.50      0.54      0.52      3269\n",
      "          LU       0.52      0.47      0.50      3390\n",
      "          ZH       0.65      0.71      0.68      3870\n",
      "\n",
      "    accuracy                           0.60     14279\n",
      "   macro avg       0.60      0.59      0.59     14279\n",
      "weighted avg       0.60      0.60      0.60     14279\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          BE       0.66      0.60      0.62      1053\n",
      "          BS       0.71      0.68      0.70      1528\n",
      "          LU       0.71      0.60      0.65      1017\n",
      "          ZH       0.61      0.82      0.70       932\n",
      "\n",
      "    accuracy                           0.67      4530\n",
      "   macro avg       0.67      0.67      0.67      4530\n",
      "weighted avg       0.68      0.67      0.67      4530\n",
      "\n",
      "enable_byte_pair_tfidf:  False enable_sentence_embedding:  False enable_audio:  True\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          BE       0.99      0.99      0.99      3750\n",
      "          BS       0.99      0.98      0.98      3269\n",
      "          LU       0.98      0.98      0.98      3390\n",
      "          ZH       0.97      0.99      0.98      3870\n",
      "\n",
      "    accuracy                           0.98     14279\n",
      "   macro avg       0.98      0.98      0.98     14279\n",
      "weighted avg       0.98      0.98      0.98     14279\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          BE       0.23      0.23      0.23      1053\n",
      "          BS       0.93      0.74      0.82      1528\n",
      "          LU       0.37      0.09      0.15      1017\n",
      "          ZH       0.44      0.95      0.60       932\n",
      "\n",
      "    accuracy                           0.52      4530\n",
      "   macro avg       0.49      0.50      0.45      4530\n",
      "weighted avg       0.54      0.52      0.49      4530\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "for enable_byte_pair_tfidf in [True, False]:\n",
    "    for enable_sentence_embedding in [True, False]:\n",
    "        for enable_audio in [True, False]:\n",
    "            if not(enable_audio or enable_sentence_embedding or enable_sentence_embedding):\n",
    "                continue\n",
    "            print(\"enable_byte_pair_tfidf: \", enable_byte_pair_tfidf, \"enable_sentence_embedding: \", enable_sentence_embedding, \"enable_audio: \", enable_audio)\n",
    "            seperate_gaussian = sdp.SwissDialectPredictorSeperateGaussians(classifiers={\n",
    "                                                                    \"audio\": make_pipeline(GaussianNB()),\n",
    "                                                                    \"sentene_embedding\": make_pipeline(\n",
    "#                                                                        StandardScaler(),\n",
    "#                                                                        TruncatedSVD(400),\n",
    "                                                                        GaussianNB()),\n",
    "                                                                    \"byte_pair_tfidf\": svm.LinearSVC()},\n",
    "                                                                normalize_each_vector=False,\n",
    "                                                                enable_byte_pair_tfidf=enable_byte_pair_tfidf,\n",
    "                                                                enable_sentance_embedding=enable_sentence_embedding,\n",
    "                                                                enable_audio=enable_audio,\n",
    "                                                               last_classifier=GaussianNB(), audio_weight=1)\n",
    "            seperate_gaussian.fit(train_df)\n",
    "            prediction_train = seperate_gaussian.predict(train_df)\n",
    "            print(classification_report(train_df[\"label\"].tolist(), prediction_train))\n",
    "            prediction_dev = seperate_gaussian.predict(dev_df)\n",
    "            print(classification_report(dev_df[\"label\"].tolist(), prediction_dev))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enable_byte_pair_tfidf:  True enable_sentence_embedding:  True enable_audio:  True\n",
      "\n",
      "\n",
      "\n",
      "tf-idf vocab size: 680\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          BE       0.87      0.89      0.88      3750\n",
      "          BS       0.88      0.85      0.86      3269\n",
      "          LU       0.82      0.87      0.84      3390\n",
      "          ZH       0.90      0.85      0.87      3870\n",
      "\n",
      "    accuracy                           0.87     14279\n",
      "   macro avg       0.87      0.87      0.87     14279\n",
      "weighted avg       0.87      0.87      0.87     14279\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          BE       0.63      0.59      0.61      1053\n",
      "          BS       0.80      0.77      0.79      1528\n",
      "          LU       0.61      0.48      0.54      1017\n",
      "          ZH       0.65      0.89      0.75       932\n",
      "\n",
      "    accuracy                           0.69      4530\n",
      "   macro avg       0.67      0.68      0.67      4530\n",
      "weighted avg       0.69      0.69      0.68      4530\n",
      "\n",
      "enable_byte_pair_tfidf:  True enable_sentence_embedding:  True enable_audio:  False\n",
      "\n",
      "\n",
      "\n",
      "tf-idf vocab size: 680\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          BE       0.79      0.83      0.81      3750\n",
      "          BS       0.77      0.73      0.75      3269\n",
      "          LU       0.78      0.70      0.74      3390\n",
      "          ZH       0.75      0.82      0.79      3870\n",
      "\n",
      "    accuracy                           0.77     14279\n",
      "   macro avg       0.77      0.77      0.77     14279\n",
      "weighted avg       0.77      0.77      0.77     14279\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          BE       0.62      0.65      0.64      1053\n",
      "          BS       0.76      0.66      0.70      1528\n",
      "          LU       0.64      0.50      0.56      1017\n",
      "          ZH       0.61      0.86      0.71       932\n",
      "\n",
      "    accuracy                           0.66      4530\n",
      "   macro avg       0.66      0.67      0.65      4530\n",
      "weighted avg       0.67      0.66      0.66      4530\n",
      "\n",
      "enable_byte_pair_tfidf:  True enable_sentence_embedding:  False enable_audio:  True\n",
      "\n",
      "\n",
      "\n",
      "tf-idf vocab size: 680\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          BE       0.99      0.99      0.99      3750\n",
      "          BS       0.99      0.98      0.99      3269\n",
      "          LU       0.99      0.98      0.98      3390\n",
      "          ZH       0.97      0.99      0.98      3870\n",
      "\n",
      "    accuracy                           0.99     14279\n",
      "   macro avg       0.99      0.99      0.99     14279\n",
      "weighted avg       0.99      0.99      0.99     14279\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          BE       0.28      0.29      0.29      1053\n",
      "          BS       0.94      0.77      0.85      1528\n",
      "          LU       0.48      0.12      0.19      1017\n",
      "          ZH       0.46      0.97      0.63       932\n",
      "\n",
      "    accuracy                           0.55      4530\n",
      "   macro avg       0.54      0.54      0.49      4530\n",
      "weighted avg       0.59      0.55      0.52      4530\n",
      "\n",
      "enable_byte_pair_tfidf:  False enable_sentence_embedding:  True enable_audio:  True\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          BE       0.99      0.67      0.80      3750\n",
      "          BS       0.98      0.60      0.74      3269\n",
      "          LU       0.49      0.99      0.65      3390\n",
      "          ZH       0.99      0.73      0.84      3870\n",
      "\n",
      "    accuracy                           0.75     14279\n",
      "   macro avg       0.86      0.75      0.76     14279\n",
      "weighted avg       0.87      0.75      0.76     14279\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          BE       0.66      0.26      0.38      1053\n",
      "          BS       0.95      0.65      0.77      1528\n",
      "          LU       0.42      0.80      0.55      1017\n",
      "          ZH       0.70      0.83      0.76       932\n",
      "\n",
      "    accuracy                           0.63      4530\n",
      "   macro avg       0.68      0.64      0.61      4530\n",
      "weighted avg       0.71      0.63      0.63      4530\n",
      "\n",
      "enable_byte_pair_tfidf:  False enable_sentence_embedding:  True enable_audio:  False\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          BE       0.71      0.65      0.68      3750\n",
      "          BS       0.50      0.54      0.52      3269\n",
      "          LU       0.52      0.47      0.50      3390\n",
      "          ZH       0.65      0.71      0.68      3870\n",
      "\n",
      "    accuracy                           0.60     14279\n",
      "   macro avg       0.60      0.59      0.59     14279\n",
      "weighted avg       0.60      0.60      0.60     14279\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          BE       0.66      0.60      0.62      1053\n",
      "          BS       0.71      0.68      0.69      1528\n",
      "          LU       0.71      0.60      0.65      1017\n",
      "          ZH       0.61      0.82      0.70       932\n",
      "\n",
      "    accuracy                           0.67      4530\n",
      "   macro avg       0.67      0.67      0.67      4530\n",
      "weighted avg       0.68      0.67      0.67      4530\n",
      "\n",
      "enable_byte_pair_tfidf:  False enable_sentence_embedding:  False enable_audio:  True\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          BE       0.99      0.98      0.99      3750\n",
      "          BS       0.99      0.98      0.98      3269\n",
      "          LU       0.99      0.98      0.98      3390\n",
      "          ZH       0.97      0.99      0.98      3870\n",
      "\n",
      "    accuracy                           0.98     14279\n",
      "   macro avg       0.98      0.98      0.98     14279\n",
      "weighted avg       0.98      0.98      0.98     14279\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          BE       0.23      0.22      0.22      1053\n",
      "          BS       0.93      0.71      0.81      1528\n",
      "          LU       0.37      0.08      0.13      1017\n",
      "          ZH       0.42      0.96      0.58       932\n",
      "\n",
      "    accuracy                           0.51      4530\n",
      "   macro avg       0.49      0.49      0.44      4530\n",
      "weighted avg       0.54      0.51      0.47      4530\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "for enable_byte_pair_tfidf in [True, False]:\n",
    "    for enable_sentence_embedding in [True, False]:\n",
    "        for enable_audio in [True, False]:\n",
    "            if not(enable_audio or enable_sentence_embedding or enable_sentence_embedding):\n",
    "                continue\n",
    "            print(\"enable_byte_pair_tfidf: \", enable_byte_pair_tfidf, \"enable_sentence_embedding: \", enable_sentence_embedding, \"enable_audio: \", enable_audio)\n",
    "            seperate_gaussian = sdp.SwissDialectPredictorSeperateGaussians(classifiers={\n",
    "                                                                    \"audio\": make_pipeline(GaussianNB()),\n",
    "                                                                    \"sentene_embedding\": make_pipeline(\n",
    "#                                                                        StandardScaler(),\n",
    "#                                                                        TruncatedSVD(400),\n",
    "                                                                        GaussianNB()),\n",
    "                                                                    \"byte_pair_tfidf\": svm.LinearSVC()},\n",
    "                                                                normalize_each_vector=False,\n",
    "                                                                enable_byte_pair_tfidf=enable_byte_pair_tfidf,\n",
    "                                                                enable_sentance_embedding=enable_sentence_embedding,\n",
    "                                                                enable_audio=enable_audio,\n",
    "                                                               last_classifier=svm.LinearSVC(), audio_weight=1)\n",
    "            seperate_gaussian.fit(train_df)\n",
    "            prediction_train = seperate_gaussian.predict(train_df)\n",
    "            print(classification_report(train_df[\"label\"].tolist(), prediction_train))\n",
    "            prediction_dev = seperate_gaussian.predict(dev_df)\n",
    "            print(classification_report(dev_df[\"label\"].tolist(), prediction_dev))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "array([-5.94933033e-01, -3.14741343e-01, -2.37563998e-01,  2.25697726e-01,\n        1.91635162e-01,  7.21708596e-01, -5.51033244e-02, -1.44991800e-01,\n        2.61286288e-01,  5.17926335e-01, -2.01473996e-01,  1.44555017e-01,\n       -2.11384326e-01, -4.37823862e-01,  8.50655958e-02,  1.30055621e-01,\n       -1.59571350e-01, -2.58173913e-01, -4.41073142e-02, -3.10205128e-02,\n       -8.72448087e-02, -6.66615605e-01,  1.94224864e-01, -6.16285205e-01,\n        3.14802378e-01,  3.69389504e-01, -2.53053904e-01,  2.39723399e-01,\n        1.85116202e-01,  1.30352348e-01,  9.32967663e-03, -5.90686560e-01,\n        3.99010926e-02, -1.57236010e-01, -3.46788943e-01, -1.90028936e-01,\n       -8.91360417e-02, -2.80196704e-02, -8.48822966e-02, -9.22569484e-02,\n       -2.65120566e-01, -3.26919705e-02, -1.98382631e-01, -6.85841739e-02,\n        1.70206025e-01,  1.56298906e-01, -4.78374183e-01, -2.37082466e-01,\n       -2.49887049e-01,  7.28962541e-01,  7.30585307e-02, -2.83880055e-01,\n       -7.10680336e-03,  6.78757727e-02, -5.00238538e-02,  1.59511283e-01,\n       -2.24926308e-01,  2.30266631e-01, -1.73869640e-01, -1.29300088e-01,\n       -2.58561015e-01, -2.28271820e-04, -4.40187544e-01, -1.40261218e-01,\n        7.13729441e-01, -2.34440580e-01, -4.93882716e-01, -2.12811470e-01,\n       -2.97652781e-01, -2.14364290e-01, -1.07787085e+00, -2.35785767e-01,\n        2.59016566e-02, -2.94062078e-01, -7.36262619e-01,  4.67518896e-01,\n       -5.53329289e-03,  9.05500501e-02,  2.07618713e-01, -9.08189118e-02,\n       -4.55960304e-01,  1.08483806e-03,  1.82886854e-01,  1.36182904e-02,\n       -3.85742635e-01, -2.16969952e-01, -2.34501287e-02, -3.73824656e-01,\n        3.96424621e-01,  1.07171118e-01, -1.23475783e-01, -4.59342033e-01,\n       -1.60560355e-01,  1.99259043e-01, -3.46980870e-01,  6.31509721e-02,\n       -1.33580491e-01, -2.75645703e-01, -1.25071146e-02,  1.30650401e-01,\n        2.87450075e-01,  2.64081180e-01,  2.33011425e-01, -4.44254786e-01,\n       -9.22663808e-02, -2.78448850e-01, -2.86576807e-01,  1.44010544e-01,\n       -3.71555984e-03, -5.60063720e-01, -2.40409121e-01,  2.68646121e-01,\n        5.65403998e-01, -1.09624721e-01,  2.60925263e-01,  1.72587559e-01,\n       -2.20162407e-01, -1.45999402e-01, -2.23239735e-01, -1.99445337e-01,\n       -2.70480752e-01,  4.63324249e-01,  3.59186321e-01, -7.50438869e-02,\n        2.23275229e-01,  6.09466314e-01, -2.35867754e-01, -8.18175450e-03,\n       -4.57806200e-01, -4.76664126e-01,  5.44553697e-02, -1.83846831e-01,\n        1.57613054e-01, -4.03140113e-03,  1.02891102e-01,  7.15719014e-02,\n        2.35787272e-01,  8.94798040e-02, -2.69803077e-01,  2.39401072e-01,\n       -1.30796492e-01, -2.36658990e-01, -4.66364086e-01,  1.42665267e-01,\n        4.73652303e-01, -1.49236247e-02, -8.38653818e-02,  1.97521329e-01,\n       -1.44481003e-01, -2.24936455e-01, -2.63462424e-01, -5.94343066e-01,\n       -9.47479308e-02, -4.68056887e-01,  4.17690456e-01, -3.92326623e-01,\n       -4.40731123e-02,  1.91029646e-02,  2.12177992e-01,  2.69917995e-01,\n        2.22694516e-01, -3.13939333e-01, -5.41252851e-01, -2.41513461e-01,\n       -7.60874808e-01, -2.31734484e-01, -4.14693326e-01,  3.03109288e-02,\n       -3.24000567e-01,  1.55178249e-01,  2.66048163e-01, -3.15301776e-01,\n       -3.33944708e-02, -3.62903699e-02,  1.02559850e-01, -1.25754654e-01,\n       -8.49992260e-02, -6.25747085e-01, -1.71203971e-01,  2.92369872e-01,\n        1.51686326e-01, -1.98067069e-01, -9.01641995e-02, -1.01293914e-01,\n       -1.01679063e+00, -4.69937444e-01, -8.95426124e-02, -1.38617679e-01,\n       -1.85583174e-01, -8.76407623e-02, -6.13027699e-02, -1.46633953e-01,\n       -2.37799287e-01, -2.46280104e-01, -6.51193485e-02, -3.99775147e-01,\n       -2.38923833e-01, -1.94086328e-01,  1.55733019e-01,  8.20815444e-01,\n       -1.93742216e-01, -9.73014385e-02, -3.50660682e-01, -8.34413171e-02,\n        3.34499747e-01, -4.42736074e-02, -2.14855641e-01, -1.57564878e-02,\n       -1.13320835e-01, -7.01303631e-02, -2.80543476e-01, -1.05636910e-01,\n       -2.58864760e-01, -2.62247920e-01, -4.79357690e-02, -7.10164979e-02,\n        1.11967415e-01, -3.65667760e-01, -1.63950458e-01,  3.88739794e-01,\n        7.50510842e-02,  3.20684701e-01,  1.73979163e-01, -5.10187298e-02,\n       -9.19539183e-02, -5.24829552e-02, -4.26789492e-01, -3.61884117e-01,\n        4.90450501e-01,  1.26834854e-01,  2.02552199e-01, -9.92424667e-01,\n        3.82584959e-01, -3.88016105e-02, -8.83636951e-01,  7.25969076e-02,\n       -1.71026349e-01,  6.31053150e-02, -2.85376877e-01, -1.90102041e-01,\n        2.96673775e-01, -2.61780858e-01,  1.49186894e-01,  1.72547415e-01,\n       -3.57631385e-01,  2.98927188e-01, -1.76712096e-01,  4.51535285e-01,\n        3.06184888e-01, -2.61363268e-01, -3.27729404e-01,  2.23103687e-02,\n        1.71179548e-01, -5.55681288e-01, -1.75160900e-01,  6.65915757e-03,\n       -5.65970421e-01,  8.91639888e-02, -1.09765485e-01, -4.12276946e-02,\n        2.59022713e-01, -5.14783263e-01, -2.35491470e-01,  2.17982218e-01,\n       -1.34082243e-01,  1.48738551e+00, -2.44965062e-01, -2.90536806e-02,\n        1.65008411e-01,  7.80247301e-02,  3.27303320e-01, -1.24503132e-02,\n        7.88880140e-02,  2.05651015e-01, -4.03984010e-01,  6.92921579e-02,\n        9.47567225e-02, -9.06382501e-03,  1.87078878e-01,  2.14782715e-01,\n        4.11649682e-02, -4.86691073e-02,  1.48279637e-01, -4.02282119e-01,\n        6.26860976e-01, -1.64598107e-01,  1.89996868e-01,  4.73526180e-01,\n       -1.28838979e-02, -4.15156782e-01,  4.26827490e-01, -6.11734509e-01,\n       -8.10992867e-02, -1.79434881e-01, -2.34542608e-01, -2.47555926e-01,\n        1.32697120e-01, -1.59813792e-01, -2.33303100e-01,  1.59071177e-01,\n       -8.82068098e-01, -1.66518188e+00, -3.16614807e-01, -1.72397062e-01,\n       -1.12422314e-02,  8.71813670e-02, -3.55255991e-01, -6.10037893e-02,\n       -3.11680436e-02, -1.49041444e-01,  2.08652675e-01, -8.02961648e-01,\n        3.06143999e-01, -7.14316592e-02,  2.83995569e-01,  1.90029070e-01,\n       -4.58726257e-01,  4.45651934e-02, -8.50818232e-02, -7.55164742e-01,\n        1.18369445e-01, -6.23976737e-02, -3.20043206e-01, -2.68392026e-01,\n       -6.60065040e-02, -2.60060549e-01,  9.96476263e-02, -9.42859873e-02,\n        4.08702791e-02, -2.75624752e-01,  9.87055749e-02, -2.22698286e-01,\n        9.97104794e-02,  9.06233788e-02,  9.13796127e-02,  3.59138161e-01,\n       -2.46888455e-02,  2.16898806e-02,  8.07295069e-02,  5.83872199e-02,\n       -2.07778633e-01, -2.64532894e-01, -4.25609499e-01,  5.84515184e-02,\n       -8.68830681e-01,  8.76280591e-02,  3.82107571e-02, -5.97271085e-01,\n       -9.43789631e-02,  1.63848609e-01,  2.72101015e-01, -2.07595393e-01,\n        1.60258546e-01,  5.94822466e-02,  2.93614030e-01,  9.75026563e-02,\n       -3.83124173e-01,  2.44068682e-01, -3.16553637e-02, -2.24150494e-02,\n       -1.44229233e-01,  2.40010798e-01, -4.48262900e-01, -4.04461324e-01,\n        2.05328688e-01, -1.10782176e-01,  1.34284928e-01, -3.42599422e-01,\n       -4.71009836e-02, -1.32689178e-01, -4.63497639e-01,  7.99296051e-03,\n       -4.83009703e-02, -6.19776845e-02,  2.05044776e-01, -7.65478611e-03,\n       -7.92745054e-02,  5.48077047e-01, -2.66636133e-01,  4.17059362e-02,\n       -1.28707290e+00, -3.52313221e-02,  1.04273960e-01,  3.67234200e-02,\n       -3.21605653e-01, -1.01246163e-01,  6.91306591e-02, -1.27779484e-01,\n       -2.09131047e-01,  4.88034189e-02, -4.58381802e-01,  3.06973636e-01,\n       -1.17969483e-01,  2.66782075e-01, -2.13774033e-02, -1.60591215e-01,\n       -6.76883534e-02,  4.49032336e-02,  4.68670964e-01, -2.07498088e-01,\n        8.22236091e-02, -5.69273308e-02, -1.58633918e-01, -8.08069706e-02,\n       -1.64500237e-01, -3.90226394e-01, -1.54146940e-01,  9.55160558e-02,\n        1.88308984e-01, -3.15138727e-01, -2.37464324e-01, -2.02858195e-01,\n       -2.55118966e-01,  1.01742119e-01, -5.07320046e-01, -1.23764090e-01,\n       -6.16933405e-03, -5.80851734e-03, -1.08950578e-01, -4.26736623e-01,\n       -3.92090231e-02, -4.18415666e-01,  6.58670738e-02,  2.06854761e-01,\n        2.90464684e-02, -3.92310768e-01, -2.45225608e-01,  3.25060964e-01,\n       -2.00007662e-01,  5.65720722e-04,  8.69953334e-02, -9.63364765e-02,\n        1.88167334e-01,  1.44927844e-01, -3.22174013e-01,  4.45736647e-01,\n        1.71512619e-01,  6.79407120e-01, -4.42420125e-01,  5.49949557e-02,\n       -3.02596718e-01, -1.57131940e-01,  1.92783177e-02,  1.85128599e-01,\n        1.40922397e-01,  1.89576209e-01,  9.82632786e-02,  4.26280320e-01,\n        7.06818253e-02,  1.54800162e-01,  8.00099969e-02, -1.07008927e-02,\n       -1.31597519e-01, -1.62819713e-01, -9.51238394e-01, -1.27714127e-01,\n       -2.38868803e-01, -1.89962596e-01, -7.02893883e-02, -4.21415120e-01,\n       -4.81450498e-01,  7.27683492e-03, -1.06325231e-01,  2.64531583e-01,\n       -1.84969097e-01, -5.35053313e-01,  4.05123889e-01,  2.52358735e-01,\n        6.45910203e-02, -2.18967602e-01, -1.77269125e+00,  2.53197044e-01,\n       -1.46255523e-01,  2.14891672e-01, -1.58680052e-01,  3.60969126e-01,\n        3.73506285e-02, -3.51276875e-01,  1.01270199e-01, -4.99661028e-01,\n       -1.70661092e-01, -2.59443045e-01, -5.81395514e-02, -3.14657837e-01,\n       -1.12234876e-01,  1.07362539e-01, -8.95539820e-02, -2.92495012e-01,\n       -1.22826874e-01, -2.56780922e-01, -1.36011550e-02, -8.26832712e-01,\n        9.16828215e-02,  3.90862256e-01,  9.93913561e-02, -5.50381988e-02,\n       -3.79087597e-01, -1.19778149e-01,  1.08135775e-01, -1.56059280e-01,\n       -6.47990227e-01, -1.03103265e-01, -1.45432264e-01, -1.25027627e-01,\n       -2.61119425e-01, -1.02879934e-01,  5.98217070e-01,  9.39583480e-02,\n        1.09446570e-01,  3.04647148e-01, -1.58184871e-01, -1.85479701e-01,\n       -2.09471732e-01,  9.44554061e-02, -1.45384669e-03, -2.84914821e-01,\n       -2.52241582e-01, -6.37460500e-04, -6.93271577e-01,  4.36546564e-01,\n        9.37167555e-02, -3.00839901e-01, -2.06155211e-01,  3.22820961e-01,\n       -5.16966172e-02, -1.32403389e-01, -2.79139310e-01,  9.10506099e-02,\n       -2.60938883e-01, -3.59860241e-01,  1.21718049e-01, -1.71358883e-03,\n       -3.33940983e-01,  1.50480211e-01, -1.31929457e-01,  4.19900045e-02,\n       -1.71754509e-01,  1.75227985e-01,  3.77479881e-01,  3.08793217e-01,\n       -3.27976912e-01,  2.66834795e-01, -3.28229368e-01, -5.37104964e-01,\n        3.76254842e-02, -5.58511138e-01, -5.72708607e-01, -5.61784506e-01,\n       -2.75552630e-01,  1.84649378e-01, -1.98576763e-01, -3.13660651e-01,\n        3.02812718e-02, -2.68659711e-01, -1.63679659e-01,  2.79752791e-01,\n        3.80729258e-01,  7.79740512e-02, -8.48549366e-01, -3.12349975e-01,\n        1.09086528e-01,  9.88397002e-03,  8.95613804e-02,  2.74437487e-01,\n       -3.29126537e-01, -8.67018551e-02,  1.67391270e-01, -2.72179008e-01,\n       -2.65847027e-01, -1.95923835e-01, -1.68956727e-01, -2.84398496e-01,\n       -3.23607475e-01,  2.74903774e-02,  3.62206310e-01,  5.31172790e-02,\n       -3.62637669e-01, -3.64808679e-01, -1.05639488e-01,  3.34112197e-02,\n        9.03548151e-02,  1.71771243e-01, -1.21840335e-01,  4.53689486e-01,\n        1.76034331e-01, -7.38931373e-02, -4.23998892e-01,  2.04414010e-01,\n       -1.32748857e-01, -2.28810579e-01, -1.76483214e-01,  1.29562274e-01,\n        3.18570323e-02, -3.68086062e-02, -3.28756034e-01,  5.09543624e-03,\n       -1.19012572e-01,  2.40453541e-01, -2.82556772e-01,  1.05146505e-02,\n       -1.59410983e-02, -1.29201531e-01, -2.74141133e-01,  1.95398852e-02,\n       -2.07121119e-01, -8.99818763e-02,  4.80707362e-03, -1.33950412e-01,\n        2.51428217e-01, -2.34965310e-01, -1.20954327e-02,  4.18440491e-01,\n        2.97264606e-02, -3.12308401e-01, -8.09537768e-02, -1.17121443e-01,\n       -2.20529854e-01, -1.04222432e-01,  2.54651642e+00, -3.59994113e-01,\n       -1.62395075e-01, -6.33979797e-01, -1.28411546e-01, -7.32915282e-01,\n       -5.15989475e-02, -4.49365526e-01,  9.17257741e-02,  1.82625577e-02,\n       -2.13604018e-01, -3.28102350e-01, -2.27640510e-01,  6.46942705e-02,\n       -6.46597594e-02,  4.33581054e-01, -8.60847771e-01,  1.58322111e-01,\n        1.54764444e-01,  1.85113907e-01, -1.27655119e-01,  2.07244694e-01,\n        6.27237111e-02, -5.01040816e-01, -5.51527500e-01,  3.46185714e-02,\n        1.77021876e-01,  3.16753983e-04, -1.18494295e-01,  1.76543027e-01,\n       -8.57725918e-01, -1.90286085e-01, -2.01437458e-01, -2.92684853e-01,\n       -2.81968415e-01, -4.39358428e-02,  3.08468610e-01, -2.14136660e-01,\n       -5.09362876e-01, -2.35418305e-02, -1.03951171e-01,  9.73332375e-02,\n       -3.69770303e-02, -2.16232359e-01, -5.22269845e-01, -2.58435249e-01,\n       -2.14087218e-01,  1.69836923e-01,  1.89196497e-01, -1.76645666e-02,\n       -1.24888331e-01, -3.07470053e-01, -8.89306515e-02, -2.04469025e-01,\n        2.71287203e-01, -2.07189783e-01,  1.98846281e-01,  3.49742115e-01,\n        4.91376728e-01,  1.92938790e-01,  7.50337690e-02, -2.95174003e-01,\n        9.68292728e-02, -2.18562841e-01,  6.53415024e-02, -3.16609651e-01,\n       -7.06135854e-03,  6.52119875e-01,  2.46431410e-01, -1.54328287e-01,\n        1.42572448e-01, -2.04155184e-02,  8.26204598e-01,  3.05600345e-01,\n       -5.45471311e-01,  1.42013520e-01, -1.54957414e-01,  3.74336958e-01,\n       -4.17802930e-01, -2.75111586e-01,  2.17198655e-01, -3.12269300e-01,\n        1.51354477e-01, -1.63203299e-01,  1.00859255e-01, -3.20707589e-01,\n       -4.57182378e-02,  4.53600943e-01,  7.17309192e-02, -2.57608205e-01,\n       -2.21925862e-02, -4.13593918e-01,  2.83153921e-01, -3.73866484e-02,\n       -8.03685784e-01,  3.32587898e-01,  1.80856138e-02, -4.47308272e-01,\n       -4.29436177e-01, -1.55595765e-02,  1.12995401e-01, -2.07233027e-01,\n        1.57774895e-01,  1.18799165e-01, -1.38250068e-01, -2.91694760e-01,\n       -4.62918192e-01, -1.03250444e-01,  4.06715006e-01, -5.11074841e-01,\n       -1.01636298e-01, -4.27099586e-01, -2.77676433e-01,  3.36467564e-01,\n       -1.62558317e-01,  1.30936503e-04,  2.06933320e-02,  1.45790130e-01,\n       -4.82266456e-01,  2.09799841e-01,  3.64187717e-01,  5.15788421e-03,\n       -1.59740269e-01,  1.09712750e-01, -8.49154443e-02, -2.87544250e-01,\n       -4.18251902e-02,  3.06634516e-01,  1.85718209e-01, -1.16657272e-01,\n       -5.77225149e-01, -1.88080803e-01,  5.06898403e-01,  5.20879984e-01,\n       -1.15234053e+00,  4.01602387e-01, -9.98356938e-03,  1.67310521e-01,\n        4.08238828e-01,  2.11412579e-01,  7.66363889e-02, -5.57064652e-01,\n        1.45348236e-01,  5.94191700e-02, -3.60664546e-01, -2.39283681e-01,\n        4.41852093e-01,  6.78474784e-01,  9.35625285e-02, -1.62789792e-01],\n      dtype=float32)"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "etrain_swissbert.iloc[0][\"sentence_embedding_first_state\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/raphael/opt/miniconda3/envs/swiss_dial/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "tf-idf vocab size: 680\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          BE       0.99      0.98      0.99      3750\n",
      "          BS       0.99      0.98      0.98      3269\n",
      "          LU       0.99      0.98      0.98      3390\n",
      "          ZH       0.96      0.99      0.98      3870\n",
      "\n",
      "    accuracy                           0.98     14279\n",
      "   macro avg       0.98      0.98      0.98     14279\n",
      "weighted avg       0.98      0.98      0.98     14279\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          BE       0.21      0.19      0.20      1053\n",
      "          BS       0.93      0.71      0.81      1528\n",
      "          LU       0.38      0.08      0.13      1017\n",
      "          ZH       0.41      0.96      0.57       932\n",
      "\n",
      "    accuracy                           0.50      4530\n",
      "   macro avg       0.48      0.49      0.43      4530\n",
      "weighted avg       0.53      0.50      0.47      4530\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from binary_swiss_dialect_predictor import BinarySwissDialectPredictor\n",
    "\n",
    "binary_swiss_predictor = BinarySwissDialectPredictor(  classifiers={\"audio\": GaussianNB(),\n",
    "                              \"sentene_embedding\": GaussianNB(),\n",
    "                              \"byte_pair_tfidf\": svm.LinearSVC()},\n",
    "                 enable_audio=True,\n",
    "                 enable_sentance_embedding=True,\n",
    "                 enable_byte_pair_tfidf=True,\n",
    "                 normalize_each_vector=False,\n",
    "                 last_classifier=svm.LinearSVC())\n",
    "binary_swiss_predictor.fit(train_df)\n",
    "prediction_train = binary_swiss_predictor.predict(train_df)\n",
    "print(classification_report(train_df[\"label\"].tolist(), prediction_train))\n",
    "prediction_dev = binary_swiss_predictor.predict(dev_df)\n",
    "print(classification_report(dev_df[\"label\"].tolist(), prediction_dev))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/raphael/opt/miniconda3/envs/swiss_dial/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "tf-idf vocab size: 680\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          BE       0.99      0.98      0.99      3750\n",
      "          BS       0.99      0.98      0.98      3269\n",
      "          LU       0.99      0.98      0.98      3390\n",
      "          ZH       0.96      0.99      0.98      3870\n",
      "\n",
      "    accuracy                           0.98     14279\n",
      "   macro avg       0.98      0.98      0.98     14279\n",
      "weighted avg       0.98      0.98      0.98     14279\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          BE       0.21      0.19      0.20      1053\n",
      "          BS       0.93      0.71      0.81      1528\n",
      "          LU       0.38      0.08      0.13      1017\n",
      "          ZH       0.41      0.96      0.57       932\n",
      "\n",
      "    accuracy                           0.50      4530\n",
      "   macro avg       0.48      0.49      0.43      4530\n",
      "weighted avg       0.53      0.50      0.47      4530\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from binary_swiss_dialect_predictor import BinarySwissDialectPredictor\n",
    "\n",
    "binary_swiss_predictor = BinarySwissDialectPredictor(  classifiers={\"audio\": GaussianNB(),\n",
    "                              \"sentene_embedding\": GaussianNB(),\n",
    "                              \"byte_pair_tfidf\": svm.LinearSVC()},\n",
    "                 enable_audio=True,\n",
    "                 enable_sentance_embedding=True,\n",
    "                 enable_byte_pair_tfidf=True,\n",
    "                 normalize_each_vector=False,\n",
    "                 last_classifier=GaussianNB())\n",
    "binary_swiss_predictor.fit(train_df)\n",
    "prediction_train = binary_swiss_predictor.predict(train_df)\n",
    "print(classification_report(train_df[\"label\"].tolist(), prediction_train))\n",
    "prediction_dev = binary_swiss_predictor.predict(dev_df)\n",
    "print(classification_report(dev_df[\"label\"].tolist(), prediction_dev))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "swiss_dial",
   "language": "python",
   "name": "swiss_dial"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

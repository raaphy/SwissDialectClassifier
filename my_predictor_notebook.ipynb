{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import my_predictor as mp\n",
    "import gdi_loader as gdi\n",
    "from sklearn import svm\n",
    "import bert_swiss_lm as bsl\n",
    "import itertools\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "my_predictor = mp.MyPredictor(\"train_embedding_bert_swiss_lm.feather\", \"dev_embedding_bert_swiss_lm.feather\", None)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "my_predictor.fit()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          BE       0.79      0.81      0.80      3750\n",
      "          BS       0.74      0.72      0.73      3269\n",
      "          LU       0.77      0.64      0.70      3390\n",
      "          ZH       0.74      0.86      0.80      3870\n",
      "\n",
      "    accuracy                           0.76     14279\n",
      "   macro avg       0.76      0.76      0.76     14279\n",
      "weighted avg       0.76      0.76      0.76     14279\n",
      "\n",
      "Dev set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          BE       0.63      0.62      0.63      1053\n",
      "          BS       0.71      0.58      0.64      1528\n",
      "          LU       0.64      0.49      0.55      1017\n",
      "          ZH       0.56      0.87      0.68       932\n",
      "\n",
      "    accuracy                           0.63      4530\n",
      "   macro avg       0.63      0.64      0.63      4530\n",
      "weighted avg       0.64      0.63      0.63      4530\n",
      "\n"
     ]
    }
   ],
   "source": [
    "my_predictor.predict_all()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          BE       0.78      0.83      0.81      3750\n",
      "          BS       0.74      0.73      0.73      3269\n",
      "          LU       0.74      0.67      0.71      3390\n",
      "          ZH       0.80      0.82      0.81      3870\n",
      "\n",
      "    accuracy                           0.77     14279\n",
      "   macro avg       0.76      0.76      0.76     14279\n",
      "weighted avg       0.77      0.77      0.77     14279\n",
      "\n",
      "Dev set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          BE       0.57      0.60      0.58      1053\n",
      "          BS       0.68      0.54      0.60      1528\n",
      "          LU       0.53      0.45      0.49      1017\n",
      "          ZH       0.57      0.81      0.67       932\n",
      "\n",
      "    accuracy                           0.59      4530\n",
      "   macro avg       0.59      0.60      0.58      4530\n",
      "weighted avg       0.60      0.59      0.59      4530\n",
      "\n"
     ]
    }
   ],
   "source": [
    "my_predictor_pooler = mp.MyPredictor(\"train_embedding_bert_swiss_lm.feather\",\n",
    "                                     \"dev_embedding_bert_swiss_lm.feather\",\n",
    "                                     None,\n",
    "                                     [\"sentence_embedding_first_state\", \"audio\"],\n",
    "                                     audio_length=10)\n",
    "\n",
    "my_predictor_pooler.fit()\n",
    "my_predictor_pooler.predict_all()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'s'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "File \u001B[0;32m~/opt/miniconda3/envs/swiss_dial/lib/python3.10/site-packages/pandas/core/indexes/base.py:3802\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[0;34m(self, key, method, tolerance)\u001B[0m\n\u001B[1;32m   3801\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 3802\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcasted_key\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3803\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n",
      "File \u001B[0;32m~/opt/miniconda3/envs/swiss_dial/lib/python3.10/site-packages/pandas/_libs/index.pyx:138\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m~/opt/miniconda3/envs/swiss_dial/lib/python3.10/site-packages/pandas/_libs/index.pyx:165\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mpandas/_libs/hashtable_class_helper.pxi:5745\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mpandas/_libs/hashtable_class_helper.pxi:5753\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;31mKeyError\u001B[0m: 's'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[8], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m my_predictor_with_audio \u001B[38;5;241m=\u001B[39m mp\u001B[38;5;241m.\u001B[39mMyPredictor(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain_embedding_bert_swiss_lm.feather\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdev_embedding_bert_swiss_lm.feather\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msentence_embedding_pooler\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m----> 2\u001B[0m \u001B[43mmy_predictor_with_audio\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      3\u001B[0m my_predictor_with_audio\u001B[38;5;241m.\u001B[39mpredict_all()\n",
      "File \u001B[0;32m~/development/ntnu/text_analysis/swiss/my_predictor.py:21\u001B[0m, in \u001B[0;36mMyPredictor.fit\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     19\u001B[0m training_embeddings \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mread_feather(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpath_train_embeddings)\n\u001B[1;32m     20\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclf \u001B[38;5;241m=\u001B[39m svm\u001B[38;5;241m.\u001B[39mSVC()\n\u001B[0;32m---> 21\u001B[0m embedding \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgenerate_embedding\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtraining_embeddings\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     22\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclf\u001B[38;5;241m.\u001B[39mfit(embedding\u001B[38;5;241m.\u001B[39mtolist(), training_embeddings[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlabel\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;241m.\u001B[39mtolist())\n",
      "File \u001B[0;32m~/development/ntnu/text_analysis/swiss/my_predictor.py:42\u001B[0m, in \u001B[0;36mMyPredictor.generate_embedding\u001B[0;34m(self, training_embeddings)\u001B[0m\n\u001B[1;32m     41\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mgenerate_embedding\u001B[39m(\u001B[38;5;28mself\u001B[39m, training_embeddings):\n\u001B[0;32m---> 42\u001B[0m     concatenated \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mconcat([training_embeddings[col] \u001B[38;5;28;01mfor\u001B[39;00m col \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mwhich_embedding], axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m     43\u001B[0m     \u001B[38;5;66;03m# change name of column\u001B[39;00m\n\u001B[1;32m     44\u001B[0m     concatenated\u001B[38;5;241m.\u001B[39mcolumns \u001B[38;5;241m=\u001B[39m [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124membedding\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "File \u001B[0;32m~/development/ntnu/text_analysis/swiss/my_predictor.py:42\u001B[0m, in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m     41\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mgenerate_embedding\u001B[39m(\u001B[38;5;28mself\u001B[39m, training_embeddings):\n\u001B[0;32m---> 42\u001B[0m     concatenated \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mconcat([\u001B[43mtraining_embeddings\u001B[49m\u001B[43m[\u001B[49m\u001B[43mcol\u001B[49m\u001B[43m]\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m col \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mwhich_embedding], axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m     43\u001B[0m     \u001B[38;5;66;03m# change name of column\u001B[39;00m\n\u001B[1;32m     44\u001B[0m     concatenated\u001B[38;5;241m.\u001B[39mcolumns \u001B[38;5;241m=\u001B[39m [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124membedding\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "File \u001B[0;32m~/opt/miniconda3/envs/swiss_dial/lib/python3.10/site-packages/pandas/core/frame.py:3807\u001B[0m, in \u001B[0;36mDataFrame.__getitem__\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   3805\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns\u001B[38;5;241m.\u001B[39mnlevels \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m   3806\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_getitem_multilevel(key)\n\u001B[0;32m-> 3807\u001B[0m indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3808\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_integer(indexer):\n\u001B[1;32m   3809\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m [indexer]\n",
      "File \u001B[0;32m~/opt/miniconda3/envs/swiss_dial/lib/python3.10/site-packages/pandas/core/indexes/base.py:3804\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[0;34m(self, key, method, tolerance)\u001B[0m\n\u001B[1;32m   3802\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine\u001B[38;5;241m.\u001B[39mget_loc(casted_key)\n\u001B[1;32m   3803\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[0;32m-> 3804\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01merr\u001B[39;00m\n\u001B[1;32m   3805\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[1;32m   3806\u001B[0m     \u001B[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001B[39;00m\n\u001B[1;32m   3807\u001B[0m     \u001B[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001B[39;00m\n\u001B[1;32m   3808\u001B[0m     \u001B[38;5;66;03m#  the TypeError.\u001B[39;00m\n\u001B[1;32m   3809\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_indexing_error(key)\n",
      "\u001B[0;31mKeyError\u001B[0m: 's'"
     ]
    }
   ],
   "source": [
    "my_predictor_with_audio = mp.MyPredictor(\"train_embedding_bert_swiss_lm.feather\", \"dev_embedding_bert_swiss_lm.feather\", None, \"sentence_embedding_pooler\")\n",
    "my_predictor_with_audio.fit()\n",
    "my_predictor_with_audio.predict_all()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "my_predictor_pooler.fit()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          BE       0.74      0.75      0.74      3750\n",
      "          BS       0.66      0.63      0.64      3269\n",
      "          LU       0.68      0.55      0.61      3390\n",
      "          ZH       0.68      0.81      0.74      3870\n",
      "\n",
      "    accuracy                           0.69     14279\n",
      "   macro avg       0.69      0.68      0.68     14279\n",
      "weighted avg       0.69      0.69      0.69     14279\n",
      "\n",
      "Dev set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          BE       0.61      0.61      0.61      1053\n",
      "          BS       0.71      0.57      0.64      1528\n",
      "          LU       0.66      0.49      0.56      1017\n",
      "          ZH       0.54      0.87      0.67       932\n",
      "\n",
      "    accuracy                           0.62      4530\n",
      "   macro avg       0.63      0.64      0.62      4530\n",
      "weighted avg       0.64      0.62      0.62      4530\n",
      "\n"
     ]
    }
   ],
   "source": [
    "my_predictor_pooler.predict_all()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['LU' 'BS' 'LU' 'LU' 'BE' 'ZH' 'ZH' 'LU' 'BS' 'LU' 'LU' 'BE' 'ZH' 'LU'\n",
      " 'LU' 'BE' 'LU' 'BE' 'LU' 'LU' 'BS' 'BE' 'BS' 'ZH' 'BS' 'BE' 'ZH' 'BS'\n",
      " 'BE' 'BE' 'BS' 'BS' 'BS' 'LU' 'ZH' 'BS' 'ZH' 'ZH' 'LU' 'LU' 'LU' 'ZH'\n",
      " 'ZH' 'BS' 'BE' 'ZH' 'LU' 'BS' 'LU' 'ZH' 'BE' 'ZH' 'BS' 'ZH' 'BS' 'ZH'\n",
      " 'ZH' 'BE' 'BE' 'BS' 'LU' 'BS' 'BE' 'ZH' 'ZH' 'ZH' 'LU' 'BS' 'BS' 'LU'\n",
      " 'BE' 'BS' 'ZH' 'ZH' 'ZH' 'ZH' 'BE' 'BE' 'BS' 'ZH' 'ZH' 'BE' 'BS' 'ZH'\n",
      " 'BS' 'BS' 'BS' 'BS' 'BE' 'BS' 'ZH' 'BS' 'ZH' 'ZH' 'LU' 'ZH' 'BS' 'ZH'\n",
      " 'BS' 'ZH' 'BS' 'BS' 'LU' 'BS' 'BE' 'BS' 'LU' 'ZH' 'ZH' 'BS' 'BE' 'LU'\n",
      " 'ZH' 'ZH' 'ZH' 'BE' 'BE' 'ZH' 'BS' 'ZH' 'BE' 'LU' 'BS' 'BE' 'BS' 'BS'\n",
      " 'BE' 'BS' 'BS' 'BS' 'LU' 'BE' 'ZH' 'LU' 'LU' 'BE' 'BE' 'LU' 'BE' 'ZH'\n",
      " 'BS' 'BE' 'BS' 'BS' 'BE' 'ZH' 'ZH' 'ZH' 'ZH' 'BE' 'BS' 'BS' 'ZH' 'ZH'\n",
      " 'LU' 'ZH' 'ZH' 'BS' 'BS' 'BS' 'BS' 'LU' 'BE' 'LU' 'BE' 'BS' 'BE' 'BE'\n",
      " 'ZH' 'ZH' 'LU' 'ZH' 'ZH' 'ZH' 'ZH' 'BE' 'BS' 'BE' 'BS' 'LU' 'ZH' 'LU'\n",
      " 'BE' 'BS' 'ZH' 'LU' 'BS' 'BE' 'BE' 'ZH' 'BE' 'BS' 'BE' 'BS' 'BS' 'ZH'\n",
      " 'BE' 'BE' 'BE' 'ZH' 'BS' 'LU' 'BE' 'ZH' 'BE' 'BS' 'BE' 'BS' 'ZH' 'ZH'\n",
      " 'BS' 'BS' 'BS' 'LU' 'BE' 'ZH' 'BS' 'BE' 'ZH' 'LU' 'ZH' 'BE' 'ZH' 'BS'\n",
      " 'LU' 'ZH' 'LU' 'BS' 'BS' 'ZH' 'BS' 'ZH' 'LU' 'BE' 'ZH' 'ZH' 'BS' 'BE'\n",
      " 'ZH' 'ZH' 'BS' 'ZH' 'LU' 'BS' 'LU' 'ZH' 'ZH' 'ZH' 'BS' 'LU' 'ZH' 'BE'\n",
      " 'BS' 'LU' 'ZH' 'ZH' 'BE' 'ZH' 'ZH' 'ZH' 'BE' 'LU' 'LU' 'LU' 'LU' 'BE'\n",
      " 'BE' 'ZH' 'BS' 'BE' 'ZH' 'LU' 'ZH' 'LU' 'BS' 'ZH' 'ZH' 'ZH' 'BE' 'ZH'\n",
      " 'BS' 'BE' 'BE' 'BE' 'ZH' 'BS' 'ZH' 'ZH' 'ZH' 'BE' 'LU' 'BS' 'ZH' 'BE'\n",
      " 'ZH' 'LU' 'ZH' 'BS' 'LU' 'LU' 'BE' 'LU' 'BS' 'LU' 'BE' 'BE' 'BE' 'BE'\n",
      " 'LU' 'LU' 'BE' 'ZH' 'ZH' 'ZH' 'ZH' 'BS' 'ZH' 'ZH' 'ZH' 'BS' 'ZH' 'BS'\n",
      " 'BE' 'BS' 'ZH' 'BE' 'ZH' 'BE' 'BS' 'LU' 'BS' 'ZH' 'ZH' 'ZH' 'BS' 'BS'\n",
      " 'BE' 'LU' 'ZH' 'ZH' 'LU' 'ZH' 'ZH' 'BE' 'BE' 'BE' 'BS' 'BS' 'BE' 'ZH'\n",
      " 'LU' 'ZH' 'ZH' 'BS' 'BE' 'LU' 'BE' 'BS' 'ZH' 'LU' 'BS' 'BE' 'ZH' 'BS'\n",
      " 'LU' 'BE' 'BE' 'ZH' 'ZH' 'BE' 'LU' 'BE' 'BE' 'LU' 'BS' 'LU' 'BS' 'ZH'\n",
      " 'ZH' 'BE' 'BE' 'BS' 'ZH' 'ZH' 'BS' 'BS' 'BE' 'LU' 'BE' 'BS' 'ZH' 'BE'\n",
      " 'ZH' 'LU' 'BS' 'ZH' 'ZH' 'ZH' 'ZH' 'ZH' 'BE' 'BE' 'BE' 'LU' 'BE' 'BE'\n",
      " 'BS' 'ZH' 'LU' 'ZH' 'BS' 'BE' 'BS' 'BS' 'ZH' 'BS' 'BE' 'BE' 'ZH' 'ZH'\n",
      " 'ZH' 'LU' 'ZH' 'LU' 'BE' 'BS' 'ZH' 'BS' 'BE' 'ZH' 'BS' 'ZH' 'BE' 'ZH'\n",
      " 'BE' 'BE' 'BS' 'BE' 'BS' 'BS' 'ZH' 'BE' 'BS' 'LU' 'ZH' 'BE' 'BS' 'ZH'\n",
      " 'LU' 'BE' 'LU' 'BS' 'BS' 'LU' 'BE' 'BS' 'BE' 'ZH' 'ZH' 'BS' 'BS' 'BE'\n",
      " 'ZH' 'BS' 'BS' 'BE' 'ZH' 'BS' 'BS' 'BS' 'BS' 'BE' 'BE' 'ZH' 'BE' 'ZH'\n",
      " 'ZH' 'ZH' 'BS' 'BS' 'BS' 'BS' 'ZH' 'BS' 'ZH' 'BE' 'ZH' 'LU' 'BS' 'LU'\n",
      " 'ZH' 'BE' 'BE' 'ZH' 'ZH' 'LU' 'BS' 'BE' 'LU' 'BE' 'BE' 'ZH' 'BE' 'LU'\n",
      " 'BE' 'BE' 'LU' 'ZH' 'ZH' 'ZH' 'ZH' 'ZH' 'ZH' 'ZH' 'BE' 'BE' 'BS' 'ZH'\n",
      " 'LU' 'ZH' 'BE' 'LU' 'ZH' 'BE' 'BE' 'ZH' 'BE' 'BS' 'ZH' 'BS' 'ZH' 'ZH'\n",
      " 'ZH' 'LU' 'LU' 'ZH' 'BE' 'ZH' 'LU' 'LU' 'ZH' 'ZH' 'BS' 'ZH' 'BE' 'ZH'\n",
      " 'BE' 'ZH' 'ZH' 'BS' 'BS' 'LU' 'BE' 'BS' 'BE' 'BE' 'LU' 'BE' 'ZH' 'ZH'\n",
      " 'LU' 'BS' 'BE' 'BS' 'ZH' 'LU' 'ZH' 'LU' 'BS' 'ZH' 'BE' 'ZH' 'BS' 'LU'\n",
      " 'ZH' 'BE' 'BS' 'ZH' 'BE' 'ZH' 'ZH' 'LU' 'BE' 'ZH' 'BS' 'LU' 'LU' 'ZH'\n",
      " 'ZH' 'ZH' 'ZH' 'BS' 'ZH' 'BE' 'BS' 'BE' 'BE' 'LU' 'BE' 'LU' 'BS' 'ZH'\n",
      " 'ZH' 'BS' 'ZH' 'ZH' 'ZH' 'ZH' 'ZH' 'BS' 'ZH' 'LU' 'BS' 'ZH' 'BS' 'ZH'\n",
      " 'BE' 'ZH' 'ZH' 'BS' 'ZH' 'LU' 'BE' 'BS' 'BS' 'BE' 'ZH' 'BS' 'BS' 'ZH'\n",
      " 'BS' 'ZH' 'BE' 'BE' 'ZH' 'BE' 'LU' 'BE' 'BS' 'ZH' 'BE' 'BS' 'BS' 'ZH'\n",
      " 'BE' 'BS' 'BS' 'BS' 'BE' 'BS' 'LU' 'LU' 'ZH' 'ZH' 'LU' 'BE' 'BE' 'ZH'\n",
      " 'LU' 'ZH' 'ZH' 'ZH' 'BS' 'LU' 'ZH' 'ZH' 'BS' 'ZH' 'BS' 'LU' 'ZH' 'LU'\n",
      " 'LU' 'ZH' 'LU' 'ZH' 'BE' 'BE' 'BS' 'BS' 'ZH' 'ZH' 'ZH' 'BS' 'LU' 'BE'\n",
      " 'BS' 'BE' 'BE' 'ZH' 'ZH' 'ZH' 'ZH' 'BS' 'BE' 'LU' 'BE' 'BS' 'BS' 'LU'\n",
      " 'ZH' 'BE' 'LU' 'ZH' 'ZH' 'LU' 'LU' 'ZH' 'BS' 'ZH' 'ZH' 'ZH' 'LU' 'LU'\n",
      " 'LU' 'BE' 'ZH' 'BE' 'ZH' 'BS' 'BS' 'BS' 'BE' 'BE' 'ZH' 'LU' 'BS' 'BE'\n",
      " 'BS' 'BS' 'BS' 'BE' 'BE' 'BE' 'LU' 'BE' 'BE' 'BE' 'BE' 'ZH' 'BS' 'ZH'\n",
      " 'BS' 'BS' 'LU' 'BE' 'BS' 'ZH' 'ZH' 'BE' 'ZH' 'ZH' 'BS' 'ZH' 'BE' 'BS'\n",
      " 'BE' 'BE' 'BS' 'BE' 'BE' 'LU' 'ZH' 'BE' 'LU' 'BE' 'ZH' 'ZH' 'BS' 'ZH'\n",
      " 'BS' 'ZH' 'BS' 'LU' 'ZH' 'BS' 'LU' 'BS' 'BE' 'ZH' 'BE' 'ZH' 'LU' 'BE'\n",
      " 'LU' 'LU' 'BS' 'BE' 'ZH' 'LU' 'ZH' 'BS' 'ZH' 'ZH' 'BS' 'ZH' 'ZH' 'BS'\n",
      " 'BE' 'ZH' 'LU' 'BS' 'LU' 'BE' 'ZH' 'ZH' 'LU' 'LU' 'ZH' 'ZH' 'BS' 'BS'\n",
      " 'BE' 'ZH' 'BS' 'LU' 'ZH' 'BE' 'ZH' 'BE' 'ZH' 'ZH' 'BS' 'BE' 'LU' 'BE'\n",
      " 'ZH' 'ZH' 'BS' 'BE' 'BE' 'ZH' 'BE' 'BS' 'BS' 'BE' 'ZH' 'ZH' 'ZH' 'BS'\n",
      " 'ZH' 'BE' 'ZH' 'ZH' 'BE' 'BE' 'BE' 'BS' 'BS' 'ZH' 'BE' 'LU' 'BS' 'BS'\n",
      " 'ZH' 'BE' 'BE' 'ZH' 'BE' 'ZH' 'ZH' 'ZH' 'ZH' 'BE' 'LU' 'BS' 'BE' 'BE'\n",
      " 'BE' 'BE' 'LU' 'ZH' 'BE' 'BS' 'LU' 'BE' 'LU' 'BE' 'BS' 'BE' 'ZH' 'ZH'\n",
      " 'BE' 'BS' 'BS' 'BE' 'BS' 'BE' 'BS' 'BE' 'BS' 'BS' 'ZH' 'BE' 'BE' 'BS'\n",
      " 'ZH' 'LU' 'LU' 'BE' 'ZH' 'ZH' 'LU' 'BE' 'LU' 'BS' 'BE' 'BS' 'ZH' 'BS'\n",
      " 'LU' 'ZH' 'BE' 'ZH' 'BE' 'BE' 'ZH' 'BS' 'LU' 'BE' 'ZH' 'LU' 'ZH' 'ZH'\n",
      " 'BE' 'LU' 'LU' 'LU' 'LU' 'BS' 'LU' 'LU' 'ZH' 'ZH' 'BS' 'ZH' 'BS' 'BS'\n",
      " 'BS' 'ZH' 'BS' 'BS' 'LU' 'LU' 'BE' 'BE' 'ZH' 'BE' 'BE' 'ZH' 'BS' 'ZH'\n",
      " 'BE' 'BS' 'BS' 'LU' 'BE' 'BE' 'BE' 'ZH' 'ZH' 'LU' 'ZH' 'LU' 'BS' 'BS'\n",
      " 'BE' 'ZH' 'ZH' 'BE' 'BS' 'LU' 'BS' 'ZH' 'BE' 'ZH' 'BE' 'ZH' 'BS' 'BS'\n",
      " 'LU' 'BS' 'LU' 'LU' 'ZH' 'BS' 'BE' 'BS' 'BS' 'ZH' 'ZH' 'ZH' 'BS' 'BS'\n",
      " 'ZH' 'LU' 'BS' 'BS' 'BS' 'BE']\n",
      "['LU', 'LU', 'LU', 'LU', 'BE', 'ZH', 'ZH', 'LU', 'BS', 'LU', 'LU', 'BE', 'BS', 'BS', 'LU', 'BS', 'LU', 'BS', 'BS', 'LU', 'BS', 'BE', 'BS', 'ZH', 'BS', 'BS', 'BE', 'ZH', 'BE', 'ZH', 'BS', 'ZH', 'BS', 'BS', 'ZH', 'BS', 'ZH', 'ZH', 'LU', 'LU', 'LU', 'ZH', 'BS', 'BS', 'BE', 'ZH', 'LU', 'BS', 'BS', 'BE', 'LU', 'ZH', 'BS', 'ZH', 'BS', 'BS', 'BS', 'BE', 'BE', 'BS', 'LU', 'BS', 'BS', 'ZH', 'BE', 'ZH', 'LU', 'LU', 'BS', 'LU', 'BE', 'BE', 'ZH', 'ZH', 'BS', 'BS', 'BE', 'BS', 'BS', 'ZH', 'LU', 'BE', 'LU', 'ZH', 'BS', 'BS', 'BS', 'BS', 'BS', 'BS', 'BE', 'LU', 'BE', 'ZH', 'LU', 'ZH', 'BS', 'ZH', 'BS', 'ZH', 'BS', 'BS', 'LU', 'BS', 'BE', 'BS', 'BS', 'BS', 'LU', 'BS', 'BE', 'LU', 'ZH', 'ZH', 'LU', 'BE', 'BE', 'ZH', 'BS', 'ZH', 'LU', 'LU', 'BS', 'LU', 'BS', 'BS', 'BE', 'BS', 'ZH', 'BE', 'BS', 'BE', 'ZH', 'LU', 'LU', 'LU', 'BS', 'BS', 'BS', 'LU', 'BS', 'BE', 'BS', 'BS', 'BE', 'BS', 'ZH', 'BE', 'BS', 'BS', 'LU', 'BS', 'BE', 'BS', 'LU', 'BE', 'ZH', 'BS', 'BS', 'BS', 'BS', 'ZH', 'BE', 'BS', 'BE', 'BE', 'BE', 'BE', 'ZH', 'ZH', 'LU', 'ZH', 'ZH', 'ZH', 'ZH', 'BE', 'BS', 'LU', 'BS', 'LU', 'BE', 'LU', 'BE', 'BS', 'BE', 'LU', 'BS', 'BE', 'BE', 'ZH', 'BS', 'LU', 'BE', 'LU', 'BS', 'ZH', 'BE', 'BE', 'BE', 'BE', 'BS', 'BS', 'BE', 'ZH', 'LU', 'BE', 'BE', 'BE', 'BE', 'BE', 'BS', 'BS', 'LU', 'BS', 'BS', 'ZH', 'BS', 'BE', 'ZH', 'LU', 'LU', 'BS', 'ZH', 'BS', 'BE', 'LU', 'LU', 'ZH', 'BS', 'BS', 'ZH', 'ZH', 'BS', 'BE', 'ZH', 'ZH', 'BS', 'BE', 'ZH', 'ZH', 'LU', 'ZH', 'LU', 'BS', 'BS', 'BE', 'ZH', 'BE', 'BS', 'LU', 'ZH', 'BE', 'BS', 'BE', 'BS', 'BS', 'BE', 'LU', 'ZH', 'ZH', 'BE', 'LU', 'LU', 'BS', 'LU', 'BE', 'LU', 'BE', 'BS', 'BE', 'ZH', 'BE', 'LU', 'LU', 'LU', 'BE', 'BS', 'BE', 'BE', 'LU', 'BS', 'BS', 'BS', 'BE', 'BE', 'BS', 'LU', 'BS', 'LU', 'BE', 'LU', 'BS', 'BE', 'LU', 'BS', 'BS', 'BE', 'BS', 'LU', 'LU', 'BE', 'LU', 'BS', 'LU', 'BE', 'BE', 'BE', 'BE', 'BE', 'ZH', 'BS', 'ZH', 'LU', 'ZH', 'ZH', 'ZH', 'ZH', 'BE', 'BS', 'LU', 'ZH', 'BS', 'BE', 'BS', 'ZH', 'BE', 'LU', 'BE', 'BS', 'LU', 'BS', 'ZH', 'ZH', 'ZH', 'BS', 'BE', 'BE', 'LU', 'LU', 'ZH', 'LU', 'ZH', 'BS', 'BE', 'LU', 'BE', 'BS', 'BS', 'BE', 'BE', 'LU', 'ZH', 'BE', 'BS', 'BE', 'LU', 'LU', 'BS', 'ZH', 'LU', 'BS', 'LU', 'BS', 'BS', 'BE', 'BE', 'ZH', 'BE', 'LU', 'BE', 'LU', 'ZH', 'BE', 'BS', 'BS', 'LU', 'BS', 'ZH', 'ZH', 'ZH', 'BE', 'BS', 'ZH', 'BS', 'BS', 'LU', 'BE', 'LU', 'BE', 'BS', 'ZH', 'BS', 'BS', 'ZH', 'LU', 'ZH', 'ZH', 'BS', 'ZH', 'LU', 'ZH', 'BS', 'BS', 'LU', 'BE', 'BE', 'LU', 'ZH', 'BS', 'BS', 'BE', 'BE', 'BS', 'BS', 'BS', 'BS', 'BE', 'BE', 'ZH', 'ZH', 'ZH', 'LU', 'BS', 'LU', 'BE', 'BS', 'ZH', 'BS', 'BE', 'ZH', 'BS', 'ZH', 'LU', 'ZH', 'BS', 'BS', 'LU', 'BE', 'BS', 'BS', 'BE', 'BE', 'BS', 'LU', 'BS', 'BE', 'LU', 'ZH', 'LU', 'BE', 'BE', 'BS', 'BS', 'BS', 'BE', 'BS', 'BE', 'BS', 'ZH', 'BS', 'ZH', 'BS', 'ZH', 'BS', 'ZH', 'BS', 'LU', 'BE', 'BS', 'LU', 'BS', 'ZH', 'BS', 'ZH', 'BS', 'ZH', 'ZH', 'BS', 'BS', 'BS', 'BS', 'ZH', 'BE', 'BS', 'BS', 'LU', 'BE', 'LU', 'BS', 'LU', 'ZH', 'LU', 'BE', 'ZH', 'ZH', 'LU', 'ZH', 'ZH', 'LU', 'BE', 'BS', 'LU', 'LU', 'LU', 'BE', 'BE', 'BS', 'BE', 'ZH', 'LU', 'LU', 'ZH', 'BE', 'BS', 'BS', 'BE', 'BE', 'BS', 'LU', 'BS', 'BE', 'BS', 'ZH', 'BE', 'BS', 'BS', 'LU', 'BS', 'BS', 'LU', 'ZH', 'ZH', 'ZH', 'LU', 'LU', 'ZH', 'BE', 'BS', 'BE', 'LU', 'ZH', 'LU', 'ZH', 'ZH', 'BE', 'BE', 'BE', 'LU', 'BS', 'LU', 'BS', 'LU', 'BS', 'BS', 'ZH', 'BE', 'LU', 'LU', 'BE', 'ZH', 'BS', 'LU', 'ZH', 'LU', 'ZH', 'LU', 'LU', 'BS', 'BS', 'BS', 'BE', 'BE', 'BE', 'BS', 'BS', 'BE', 'BS', 'BS', 'BE', 'ZH', 'BS', 'BS', 'BE', 'BE', 'BS', 'LU', 'BE', 'ZH', 'ZH', 'BE', 'BE', 'BS', 'ZH', 'BE', 'BS', 'ZH', 'BE', 'LU', 'LU', 'LU', 'LU', 'ZH', 'ZH', 'LU', 'ZH', 'BE', 'ZH', 'BS', 'ZH', 'LU', 'BS', 'BE', 'BS', 'LU', 'BS', 'BS', 'LU', 'ZH', 'LU', 'BS', 'ZH', 'BS', 'BE', 'BS', 'BE', 'BE', 'BE', 'BE', 'BS', 'BS', 'LU', 'ZH', 'BE', 'BE', 'BE', 'BE', 'LU', 'BE', 'BS', 'ZH', 'BS', 'LU', 'BS', 'LU', 'BE', 'BS', 'BS', 'BE', 'BE', 'BS', 'LU', 'LU', 'ZH', 'BE', 'LU', 'BS', 'BS', 'ZH', 'LU', 'LU', 'ZH', 'LU', 'BS', 'BS', 'BE', 'ZH', 'BS', 'BS', 'LU', 'LU', 'ZH', 'BE', 'BE', 'ZH', 'BS', 'ZH', 'BE', 'BE', 'BS', 'BS', 'ZH', 'BS', 'BE', 'BE', 'LU', 'LU', 'BS', 'LU', 'BE', 'ZH', 'BS', 'ZH', 'BE', 'LU', 'LU', 'BS', 'BE', 'BE', 'LU', 'LU', 'BS', 'LU', 'LU', 'BS', 'BE', 'BS', 'LU', 'LU', 'BS', 'ZH', 'ZH', 'LU', 'LU', 'LU', 'BE', 'BE', 'BS', 'BE', 'BS', 'BE', 'BS', 'BS', 'BE', 'BE', 'BS', 'LU', 'LU', 'BE', 'LU', 'LU', 'BS', 'BE', 'BE', 'BE', 'LU', 'BE', 'LU', 'BE', 'ZH', 'BE', 'BS', 'ZH', 'LU', 'BS', 'LU', 'LU', 'BS', 'LU', 'LU', 'BE', 'BE', 'BE', 'BS', 'LU', 'LU', 'BS', 'BE', 'BE', 'BS', 'BE', 'BS', 'BE', 'BS', 'BE', 'LU', 'BE', 'ZH', 'ZH', 'ZH', 'ZH', 'ZH', 'ZH', 'ZH', 'BS', 'ZH', 'BE', 'BS', 'BS', 'BE', 'BS', 'BE', 'ZH', 'LU', 'BE', 'LU', 'LU', 'BS', 'BS', 'ZH', 'LU', 'LU', 'BS', 'BS', 'ZH', 'BS', 'BS', 'BE', 'BS', 'LU', 'BE', 'LU', 'BS', 'LU', 'LU', 'ZH', 'BS', 'LU', 'LU', 'BS', 'BE', 'LU', 'LU', 'BE', 'BS', 'ZH', 'LU', 'ZH', 'BS', 'ZH', 'LU', 'LU', 'ZH', 'BS', 'BE', 'LU', 'BE', 'BS', 'ZH', 'BS', 'BE', 'BS', 'BE', 'BE', 'BS', 'BS', 'BS', 'ZH', 'BS', 'ZH', 'BS', 'BS', 'ZH', 'ZH', 'LU', 'BE', 'BE', 'BE', 'LU', 'BS', 'ZH', 'BS', 'LU', 'BS', 'BS', 'ZH', 'BE', 'BS', 'BE', 'BE', 'ZH', 'BS', 'BE', 'ZH', 'BS', 'BS', 'BS', 'BS', 'BS', 'BE', 'BE', 'LU', 'BS', 'BE', 'LU', 'LU', 'BE', 'LU', 'BS', 'LU', 'BS', 'BS', 'BS', 'LU', 'BS', 'BS', 'LU', 'BE', 'BS', 'LU', 'BS', 'BS', 'BS', 'BE', 'BE', 'BE', 'BS', 'ZH', 'LU', 'LU', 'BS', 'BS', 'ZH', 'BS', 'BS', 'LU', 'BE', 'LU', 'BS', 'ZH', 'BS', 'LU', 'BS', 'BE', 'ZH', 'BE', 'LU', 'ZH', 'BS', 'LU', 'LU', 'BE', 'LU', 'LU', 'ZH', 'LU', 'LU', 'BS', 'LU', 'LU', 'BS', 'LU', 'BS', 'ZH', 'BS', 'LU', 'ZH', 'BS', 'BS', 'BS', 'BS', 'BE', 'BS', 'LU', 'LU', 'ZH', 'BE', 'BS', 'BE', 'BE', 'ZH', 'BS', 'LU', 'BE', 'BS', 'BS', 'BS', 'BS', 'BE', 'LU', 'BS', 'ZH', 'LU', 'ZH', 'LU', 'BS', 'BS', 'LU', 'ZH', 'BE', 'BE', 'BE', 'LU', 'BE', 'LU', 'BS', 'LU', 'BE', 'LU', 'BS', 'BS', 'BS', 'BS', 'LU', 'BS', 'ZH', 'BS', 'BE', 'BS', 'BS', 'BE', 'BS', 'LU', 'BS', 'BS', 'BS', 'LU', 'BS', 'BS', 'BS', 'BE']\n"
     ]
    }
   ],
   "source": [
    "prediction_dev = clf.predict(embdedings_numpy_dev)\n",
    "print(prediction_dev)\n",
    "print(lables_dev)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6147505478251539\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          BE       0.60      0.62      0.61       242\n",
      "          BS       0.69      0.52      0.60       335\n",
      "          LU       0.69      0.49      0.57       235\n",
      "          ZH       0.48      0.84      0.61       188\n",
      "\n",
      "    accuracy                           0.60      1000\n",
      "   macro avg       0.61      0.62      0.60      1000\n",
      "weighted avg       0.63      0.60      0.60      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(precision_score(lables_dev, prediction_dev, average=\"macro\"))\n",
    "print(classification_report(lables_dev, prediction_dev))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "swiss_dial",
   "language": "python",
   "name": "swiss_dial"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

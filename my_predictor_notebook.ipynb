{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from tokenizers import ByteLevelBPETokenizer\n",
    "import my_predictor as mp\n",
    "import gdi_loader as gdi\n",
    "from sklearn import svm\n",
    "import bert_swiss_lm as bsl\n",
    "import itertools\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "my_predictor = mp.MyPredictor(\"train_embedding_bert_swiss_lm.feather\", \"dev_embedding_bert_swiss_lm.feather\", None)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "my_predictor.fit()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          BE       0.91      0.93      0.92      3750\n",
      "          BS       0.90      0.88      0.89      3269\n",
      "          LU       0.92      0.85      0.88      3390\n",
      "          ZH       0.89      0.95      0.92      3870\n",
      "\n",
      "    accuracy                           0.90     14279\n",
      "   macro avg       0.91      0.90      0.90     14279\n",
      "weighted avg       0.91      0.90      0.90     14279\n",
      "\n",
      "Dev set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          BE       0.63      0.62      0.62      1053\n",
      "          BS       0.71      0.59      0.65      1528\n",
      "          LU       0.61      0.47      0.53      1017\n",
      "          ZH       0.56      0.86      0.68       932\n",
      "\n",
      "    accuracy                           0.63      4530\n",
      "   macro avg       0.63      0.64      0.62      4530\n",
      "weighted avg       0.64      0.63      0.62      4530\n",
      "\n"
     ]
    }
   ],
   "source": [
    "my_predictor.predict_all()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          BE       0.78      0.83      0.81      3750\n",
      "          BS       0.74      0.73      0.73      3269\n",
      "          LU       0.74      0.67      0.71      3390\n",
      "          ZH       0.80      0.82      0.81      3870\n",
      "\n",
      "    accuracy                           0.77     14279\n",
      "   macro avg       0.76      0.76      0.76     14279\n",
      "weighted avg       0.77      0.77      0.77     14279\n",
      "\n",
      "Dev set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          BE       0.57      0.60      0.58      1053\n",
      "          BS       0.68      0.54      0.60      1528\n",
      "          LU       0.53      0.45      0.49      1017\n",
      "          ZH       0.57      0.81      0.67       932\n",
      "\n",
      "    accuracy                           0.59      4530\n",
      "   macro avg       0.59      0.60      0.58      4530\n",
      "weighted avg       0.60      0.59      0.59      4530\n",
      "\n"
     ]
    }
   ],
   "source": [
    "my_predictor_pooler = mp.MyPredictor(\"train_embedding_bert_swiss_lm.feather\",\n",
    "                                     \"dev_embedding_bert_swiss_lm.feather\",\n",
    "                                     None,\n",
    "                                     [\"sentence_embedding_first_state\", \"audio\"],\n",
    "                                     audio_length=10)\n",
    "\n",
    "my_predictor_pooler.fit()\n",
    "my_predictor_pooler.predict_all()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'s'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "File \u001B[0;32m~/opt/miniconda3/envs/swiss_dial/lib/python3.10/site-packages/pandas/core/indexes/base.py:3802\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[0;34m(self, key, method, tolerance)\u001B[0m\n\u001B[1;32m   3801\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 3802\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcasted_key\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3803\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n",
      "File \u001B[0;32m~/opt/miniconda3/envs/swiss_dial/lib/python3.10/site-packages/pandas/_libs/index.pyx:138\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m~/opt/miniconda3/envs/swiss_dial/lib/python3.10/site-packages/pandas/_libs/index.pyx:165\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mpandas/_libs/hashtable_class_helper.pxi:5745\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mpandas/_libs/hashtable_class_helper.pxi:5753\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;31mKeyError\u001B[0m: 's'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[8], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m my_predictor_with_audio \u001B[38;5;241m=\u001B[39m mp\u001B[38;5;241m.\u001B[39mMyPredictor(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain_embedding_bert_swiss_lm.feather\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdev_embedding_bert_swiss_lm.feather\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msentence_embedding_pooler\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m----> 2\u001B[0m \u001B[43mmy_predictor_with_audio\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      3\u001B[0m my_predictor_with_audio\u001B[38;5;241m.\u001B[39mpredict_all()\n",
      "File \u001B[0;32m~/development/ntnu/text_analysis/swiss/my_predictor.py:21\u001B[0m, in \u001B[0;36mMyPredictor.fit\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     19\u001B[0m training_embeddings \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mread_feather(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpath_train_embeddings)\n\u001B[1;32m     20\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclf \u001B[38;5;241m=\u001B[39m svm\u001B[38;5;241m.\u001B[39mSVC()\n\u001B[0;32m---> 21\u001B[0m embedding \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgenerate_embedding\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtraining_embeddings\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     22\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclf\u001B[38;5;241m.\u001B[39mfit(embedding\u001B[38;5;241m.\u001B[39mtolist(), training_embeddings[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlabel\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;241m.\u001B[39mtolist())\n",
      "File \u001B[0;32m~/development/ntnu/text_analysis/swiss/my_predictor.py:42\u001B[0m, in \u001B[0;36mMyPredictor.generate_embedding\u001B[0;34m(self, training_embeddings)\u001B[0m\n\u001B[1;32m     41\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mgenerate_embedding\u001B[39m(\u001B[38;5;28mself\u001B[39m, training_embeddings):\n\u001B[0;32m---> 42\u001B[0m     concatenated \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mconcat([training_embeddings[col] \u001B[38;5;28;01mfor\u001B[39;00m col \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mwhich_embedding], axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m     43\u001B[0m     \u001B[38;5;66;03m# change name of column\u001B[39;00m\n\u001B[1;32m     44\u001B[0m     concatenated\u001B[38;5;241m.\u001B[39mcolumns \u001B[38;5;241m=\u001B[39m [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124membedding\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "File \u001B[0;32m~/development/ntnu/text_analysis/swiss/my_predictor.py:42\u001B[0m, in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m     41\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mgenerate_embedding\u001B[39m(\u001B[38;5;28mself\u001B[39m, training_embeddings):\n\u001B[0;32m---> 42\u001B[0m     concatenated \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mconcat([\u001B[43mtraining_embeddings\u001B[49m\u001B[43m[\u001B[49m\u001B[43mcol\u001B[49m\u001B[43m]\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m col \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mwhich_embedding], axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m     43\u001B[0m     \u001B[38;5;66;03m# change name of column\u001B[39;00m\n\u001B[1;32m     44\u001B[0m     concatenated\u001B[38;5;241m.\u001B[39mcolumns \u001B[38;5;241m=\u001B[39m [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124membedding\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "File \u001B[0;32m~/opt/miniconda3/envs/swiss_dial/lib/python3.10/site-packages/pandas/core/frame.py:3807\u001B[0m, in \u001B[0;36mDataFrame.__getitem__\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   3805\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns\u001B[38;5;241m.\u001B[39mnlevels \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m   3806\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_getitem_multilevel(key)\n\u001B[0;32m-> 3807\u001B[0m indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3808\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_integer(indexer):\n\u001B[1;32m   3809\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m [indexer]\n",
      "File \u001B[0;32m~/opt/miniconda3/envs/swiss_dial/lib/python3.10/site-packages/pandas/core/indexes/base.py:3804\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[0;34m(self, key, method, tolerance)\u001B[0m\n\u001B[1;32m   3802\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine\u001B[38;5;241m.\u001B[39mget_loc(casted_key)\n\u001B[1;32m   3803\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[0;32m-> 3804\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01merr\u001B[39;00m\n\u001B[1;32m   3805\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[1;32m   3806\u001B[0m     \u001B[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001B[39;00m\n\u001B[1;32m   3807\u001B[0m     \u001B[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001B[39;00m\n\u001B[1;32m   3808\u001B[0m     \u001B[38;5;66;03m#  the TypeError.\u001B[39;00m\n\u001B[1;32m   3809\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_indexing_error(key)\n",
      "\u001B[0;31mKeyError\u001B[0m: 's'"
     ]
    }
   ],
   "source": [
    "my_predictor_with_audio = mp.MyPredictor(\"train_embedding_bert_swiss_lm.feather\", \"dev_embedding_bert_swiss_lm.feather\", None, \"sentence_embedding_pooler\")\n",
    "my_predictor_with_audio.fit()\n",
    "my_predictor_with_audio.predict_all()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "my_predictor_pooler.fit()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:  6e-05 kernel:  linear\n",
      "Training set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          BE       0.99      0.99      0.99      3750\n",
      "          BS       0.99      0.98      0.99      3269\n",
      "          LU       0.99      1.00      0.99      3390\n",
      "          ZH       0.99      0.99      0.99      3870\n",
      "\n",
      "    accuracy                           0.99     14279\n",
      "   macro avg       0.99      0.99      0.99     14279\n",
      "weighted avg       0.99      0.99      0.99     14279\n",
      "\n",
      "Dev set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          BE       0.20      0.24      0.22      1053\n",
      "          BS       0.62      0.39      0.48      1528\n",
      "          LU       0.29      0.14      0.18      1017\n",
      "          ZH       0.38      0.73      0.50       932\n",
      "\n",
      "    accuracy                           0.37      4530\n",
      "   macro avg       0.37      0.37      0.34      4530\n",
      "weighted avg       0.40      0.37      0.36      4530\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in (0.00006,):\n",
    "    # best C: 0.00006 (macro f1 0.33)\n",
    "    # standard_Scaler= True: 0.0006 (accuracy 0.31) schlechter als 0.00006 (accuracy 0.38)\n",
    "    # standard_Scaler= False: 0.0006 (accuracy )  als normalize_each_vector=False 0.00006 (accuracy 0.31)\n",
    "#    for standard_scalar in (False, True):\n",
    "    for kernel in (\"linear\",):\n",
    "        standard_scalar = True\n",
    "        norm = False\n",
    "        my_predictor_audio = mp.MyPredictor(\"train_embedding_bert_swiss_lm.feather\",\n",
    "                                     \"dev_embedding_bert_swiss_lm.feather\",\n",
    "                                     None,\n",
    "                                            (\"audio\",),\n",
    "                                    normalize_each_vector=norm)\n",
    "\n",
    "        my_predictor_audio.fit(C=i, standard_scaler=standard_scalar, kernel=kernel)\n",
    "        print(\"C: \", i, \"kernel: \", kernel)\n",
    "        my_predictor_audio.predict_all()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "standard_scaler:  False normalize_each_vector:  False\n",
      "Training set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          BE       0.85      0.84      0.84      3750\n",
      "          BS       0.80      0.82      0.81      3269\n",
      "          LU       0.82      0.75      0.78      3390\n",
      "          ZH       0.81      0.87      0.84      3870\n",
      "\n",
      "    accuracy                           0.82     14279\n",
      "   macro avg       0.82      0.82      0.82     14279\n",
      "weighted avg       0.82      0.82      0.82     14279\n",
      "\n",
      "Dev set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          BE       0.66      0.59      0.62      1053\n",
      "          BS       0.80      0.77      0.79      1528\n",
      "          LU       0.81      0.57      0.67      1017\n",
      "          ZH       0.60      0.90      0.72       932\n",
      "\n",
      "    accuracy                           0.71      4530\n",
      "   macro avg       0.72      0.71      0.70      4530\n",
      "weighted avg       0.73      0.71      0.71      4530\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for standard_scalar in (False,):\n",
    "    for norm in (False,):\n",
    "        my_predictor_audio_gaussian = mp.MyPredictor(\"train_embedding_bert_swiss_lm.feather\",\n",
    "                                     \"dev_embedding_bert_swiss_lm.feather\",\n",
    "                                     None,\n",
    "                                                     (\"sentence_embedding_first_state\", \"audio\"),\n",
    "                                    normalize_each_vector=norm)\n",
    "\n",
    "        my_predictor_audio_gaussian.fit_gaussian_naive_bayes(standard_scaler=standard_scalar)\n",
    "        print(\"standard_scaler: \", standard_scalar, \"normalize_each_vector: \", norm)\n",
    "        my_predictor_audio_gaussian.predict_all()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6147505478251539\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          BE       0.60      0.62      0.61       242\n",
      "          BS       0.69      0.52      0.60       335\n",
      "          LU       0.69      0.49      0.57       235\n",
      "          ZH       0.48      0.84      0.61       188\n",
      "\n",
      "    accuracy                           0.60      1000\n",
      "   macro avg       0.61      0.62      0.60      1000\n",
      "weighted avg       0.63      0.60      0.60      1000\n",
      "\n"
     ]
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "1000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          BE       0.57      0.60      0.58      1053\n",
      "          BS       0.73      0.60      0.66      1528\n",
      "          LU       0.60      0.47      0.53      1017\n",
      "          ZH       0.56      0.82      0.67       932\n",
      "\n",
      "    accuracy                           0.62      4530\n",
      "   macro avg       0.62      0.62      0.61      4530\n",
      "weighted avg       0.63      0.62      0.61      4530\n",
      "\n",
      "[[-1.31001618 -0.7810659   0.86600119 -2.04481747]\n",
      " [-0.44720302  0.20401442 -1.02759569 -0.91909179]\n",
      " [-0.02500046 -0.37267663  0.1809242  -3.47945755]\n",
      " [ 0.86143844 -1.7048028  -0.58103523 -2.71862425]\n",
      " [ 0.53552571 -1.86106865 -0.65354833 -1.24230647]\n",
      " [-1.77664344 -1.62984643 -2.90404613  2.20583745]\n",
      " [-1.63378788 -0.85808199 -0.08675167  0.08348658]\n",
      " [-0.80958421 -2.19490501  1.04960575 -2.02077076]\n",
      " [-1.81817499  1.28206112 -0.93882105 -1.71235151]\n",
      " [-0.34390398 -1.44972304 -0.24034991 -1.36355317]]\n",
      "['LU' 'BS' 'LU' 'BE' 'BE' 'ZH' 'ZH' 'LU' 'BS' 'LU']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "for i in (1000,):\n",
    "    tokenizer = ByteLevelBPETokenizer()\n",
    "    df = pd.read_feather(\"train_embedding_bert_swiss_lm.feather\")\n",
    "    tokenizer.train_from_iterator(df['text'].tolist(), vocab_size=i, min_frequency=2)\n",
    "    encoded = tokenizer.encode_batch(df['text'].tolist())\n",
    "    tokenized = [e.tokens for e in encoded]\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    tfidf_weights = vectorizer.fit_transform([' '.join(tokens) for tokens in tokenized]).toarray()\n",
    "    gaus = svm.LinearSVC()\n",
    "    #gaus = svm.SVC(kernel='linear')\n",
    "    #gaus = GaussianNB()\n",
    "    #gaus = make_pipeline(StandardScaler(), gaus)\n",
    "    gaus.fit(tfidf_weights, df['label'].tolist())\n",
    "    df_dev = pd.read_feather(\"dev_embedding_bert_swiss_lm.feather\")\n",
    "    dev_tokenized = [e.tokens for e in tokenizer.encode_batch(df_dev['text'].tolist())]\n",
    "    dev_vectorized = vectorizer.transform([' '.join(tokens) for tokens in dev_tokenized]).toarray()\n",
    "    dev_predict = gaus.predict(dev_vectorized)\n",
    "  #  train_predict = gaus.predict(tfidf_weights)\n",
    "    #print(classification_report(df['label'].tolist(), train_predict))\n",
    "    print(i)\n",
    "    print(classification_report(df_dev['label'].tolist(), dev_predict))\n",
    "    print(gaus.decision_function(dev_vectorized)[0:10])\n",
    "    print(gaus.predict(dev_vectorized)[0:10])\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# For sentance_embedding and audio, GaussianNB is the best\n",
    "# For ByteLevelBPETokenizer, LinearSVC is the best\n",
    "# One can call LinearSVC.decision_function() to get features which can be used for classification"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import swiss_dialect_predictors as sdp"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "train_df = pd.read_feather(\"train_embedding_bert_swiss_lm.feather\")\n",
    "dev_df = pd.read_feather(\"dev_embedding_bert_swiss_lm.feather\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "tf-idf vocab size: 680\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          BE       0.87      0.85      0.86      3750\n",
      "          BS       0.82      0.84      0.83      3269\n",
      "          LU       0.84      0.78      0.81      3390\n",
      "          ZH       0.82      0.87      0.85      3870\n",
      "\n",
      "    accuracy                           0.84     14279\n",
      "   macro avg       0.84      0.84      0.84     14279\n",
      "weighted avg       0.84      0.84      0.84     14279\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          BE       0.67      0.62      0.64      1053\n",
      "          BS       0.81      0.79      0.80      1528\n",
      "          LU       0.82      0.58      0.68      1017\n",
      "          ZH       0.62      0.89      0.73       932\n",
      "\n",
      "    accuracy                           0.72      4530\n",
      "   macro avg       0.73      0.72      0.71      4530\n",
      "weighted avg       0.74      0.72      0.72      4530\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "svm_gaussiannb_predictor = sdp.SwissDialectPredictorSvmGaussianNB( enable_audio=True,\n",
    "                                                                   enable_sentance_embedding=True,\n",
    "                                                                   enable_byte_pair_tfidf=True,\n",
    "                                                                   normalize_each_vector=True,\n",
    "                                                                   last_classifier=GaussianNB())\n",
    "                                                                   #last_classifier=make_pipeline(StandardScaler(), TruncatedSVD(n_components=220), LinearSVC()))\n",
    "svm_gaussiannb_predictor.fit(train_df)\n",
    "train_predicted = svm_gaussiannb_predictor.predict(train_df)\n",
    "dev_predicted = svm_gaussiannb_predictor.predict(dev_df)\n",
    "# calculate f1 macro\n",
    "print(classification_report(train_df['label'].tolist(), train_predicted))\n",
    "print(classification_report(dev_df['label'].tolist(), dev_predicted))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          BE       0.43      0.73      0.54      1053\n",
      "          BS       0.72      0.56      0.63      1528\n",
      "          LU       0.70      0.27      0.39      1017\n",
      "          ZH       0.51      0.63      0.56       932\n",
      "\n",
      "    accuracy                           0.55      4530\n",
      "   macro avg       0.59      0.55      0.53      4530\n",
      "weighted avg       0.60      0.55      0.54      4530\n",
      "\n"
     ]
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "tf-idf vocab size: 680\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          BE       0.54      0.84      0.65      3750\n",
      "          BS       0.73      0.45      0.56      3269\n",
      "          LU       0.71      0.50      0.59      3390\n",
      "          ZH       0.65      0.66      0.66      3870\n",
      "\n",
      "    accuracy                           0.62     14279\n",
      "   macro avg       0.66      0.62      0.62     14279\n",
      "weighted avg       0.65      0.62      0.62     14279\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          BE       0.37      0.70      0.49      1053\n",
      "          BS       0.73      0.37      0.49      1528\n",
      "          LU       0.51      0.28      0.36      1017\n",
      "          ZH       0.48      0.62      0.54       932\n",
      "\n",
      "    accuracy                           0.48      4530\n",
      "   macro avg       0.52      0.49      0.47      4530\n",
      "weighted avg       0.55      0.48      0.47      4530\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from byte_pair_tfidf_vectorizer import BytePairTfidfVectorizer\n",
    "\n",
    "byte_pair_tfidf_vectorizer = BytePairTfidfVectorizer(vocab_size=1000, min_frequency=2)\n",
    "byte_pair_vectorized = byte_pair_tfidf_vectorizer.fit_transform(train_df[\"text\"].tolist())\n",
    "\n",
    "svm_linear = make_pipeline(StandardScaler(),TruncatedSVD(n_components=50), KNeighborsClassifier(n_neighbors=50))\n",
    "svm_linear.fit(byte_pair_vectorized, train_df[\"label\"].tolist())\n",
    "prediction = svm_linear.predict(byte_pair_vectorized)\n",
    "print(classification_report(train_df[\"label\"].tolist(), prediction))\n",
    "prediction_dev = svm_linear.predict(byte_pair_tfidf_vectorizer.transform(dev_df[\"text\"].tolist()))\n",
    "print(classification_report(dev_df[\"label\"].tolist(), prediction_dev))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "tf-idf vocab size: 680\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          BE       0.88      0.87      0.88      3750\n",
      "          BS       0.86      0.86      0.86      3269\n",
      "          LU       0.87      0.81      0.84      3390\n",
      "          ZH       0.85      0.90      0.87      3870\n",
      "\n",
      "    accuracy                           0.86     14279\n",
      "   macro avg       0.86      0.86      0.86     14279\n",
      "weighted avg       0.86      0.86      0.86     14279\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          BE       0.66      0.59      0.63      1053\n",
      "          BS       0.82      0.80      0.81      1528\n",
      "          LU       0.81      0.56      0.66      1017\n",
      "          ZH       0.61      0.91      0.73       932\n",
      "\n",
      "    accuracy                           0.72      4530\n",
      "   macro avg       0.73      0.72      0.71      4530\n",
      "weighted avg       0.74      0.72      0.72      4530\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "seperate_gaussian = sdp.SwissDialectPredictorSeperateGaussians(classifiers={\n",
    "                                                                    \"audio\": make_pipeline(GaussianNB()),\n",
    "                                                                    \"sentene_embedding\": make_pipeline(\n",
    "                                                                      #  StandardScaler(),\n",
    "                                                                      #  TruncatedSVD(20),\n",
    "                                                                        GaussianNB()),\n",
    "                                                                    \"byte_pair_tfidf\": svm.LinearSVC()},\n",
    "                                                                normalize_each_vector=True,\n",
    "                                                                enable_byte_pair_tfidf=True,\n",
    "                                                                enable_sentance_embedding=True,\n",
    "                                                                enable_audio=True,\n",
    "                                                               last_classifier=GaussianNB(), audio_weight=1.3)\n",
    "seperate_gaussian.fit(train_df)\n",
    "prediction_train = seperate_gaussian.predict(train_df)\n",
    "print(classification_report(train_df[\"label\"].tolist(), prediction_train))\n",
    "prediction_dev = seperate_gaussian.predict(dev_df)\n",
    "print(classification_report(dev_df[\"label\"].tolist(), prediction_dev))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    " ,ö"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "se"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "swiss_dial",
   "language": "python",
   "name": "swiss_dial"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
